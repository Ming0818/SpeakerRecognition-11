{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model_lpcc import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lpcc = 49 # '(n_lpcc + 1)' must be divisible by 5.\n",
    "window_size = 10\n",
    "audio_len = 600\n",
    "data_dir = os.path.join('..', 'audio-train-new')\n",
    "lpcc_shape = (10, (n_lpcc + 1) / 5, 1)\n",
    "n_samples = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running preprocess..\n",
      "Loading LPCC data..\n",
      "(37, 100)\n",
      "Building the model..\n",
      "Train on 3491 samples, validate on 1497 samples\n",
      "Epoch 1/600\n",
      "3491/3491 [==============================] - 1s 306us/step - loss: 4.7143 - acc: 0.0117 - val_loss: 4.7074 - val_acc: 0.0147\n",
      "Epoch 2/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 4.6838 - acc: 0.0178 - val_loss: 4.6843 - val_acc: 0.0073\n",
      "Epoch 3/600\n",
      "3491/3491 [==============================] - 1s 253us/step - loss: 4.6602 - acc: 0.0189 - val_loss: 4.6564 - val_acc: 0.0180\n",
      "Epoch 4/600\n",
      "3491/3491 [==============================] - 1s 255us/step - loss: 4.6337 - acc: 0.0215 - val_loss: 4.6242 - val_acc: 0.0194\n",
      "Epoch 5/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 4.6150 - acc: 0.0269 - val_loss: 4.5913 - val_acc: 0.0187\n",
      "Epoch 6/600\n",
      "3491/3491 [==============================] - 1s 258us/step - loss: 4.5775 - acc: 0.0289 - val_loss: 4.5576 - val_acc: 0.0194\n",
      "Epoch 7/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 4.5560 - acc: 0.0338 - val_loss: 4.5282 - val_acc: 0.0267\n",
      "Epoch 8/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 4.5293 - acc: 0.0335 - val_loss: 4.4890 - val_acc: 0.0341\n",
      "Epoch 9/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 4.4938 - acc: 0.0398 - val_loss: 4.4481 - val_acc: 0.0441\n",
      "Epoch 10/600\n",
      "3491/3491 [==============================] - 1s 251us/step - loss: 4.4645 - acc: 0.0441 - val_loss: 4.4102 - val_acc: 0.0468\n",
      "Epoch 11/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 4.4261 - acc: 0.0484 - val_loss: 4.3719 - val_acc: 0.0508\n",
      "Epoch 12/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 4.3721 - acc: 0.0533 - val_loss: 4.3223 - val_acc: 0.0621\n",
      "Epoch 13/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 4.3132 - acc: 0.0561 - val_loss: 4.2581 - val_acc: 0.0688\n",
      "Epoch 14/600\n",
      "3491/3491 [==============================] - 1s 252us/step - loss: 4.2457 - acc: 0.0650 - val_loss: 4.1980 - val_acc: 0.0835\n",
      "Epoch 15/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 4.2129 - acc: 0.0682 - val_loss: 4.1351 - val_acc: 0.0915\n",
      "Epoch 16/600\n",
      "3491/3491 [==============================] - 1s 255us/step - loss: 4.1742 - acc: 0.0733 - val_loss: 4.0692 - val_acc: 0.1116\n",
      "Epoch 17/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 4.1051 - acc: 0.0739 - val_loss: 4.0081 - val_acc: 0.1276\n",
      "Epoch 18/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 4.0382 - acc: 0.0845 - val_loss: 3.9487 - val_acc: 0.1356\n",
      "Epoch 19/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 4.0022 - acc: 0.0917 - val_loss: 3.8825 - val_acc: 0.1456\n",
      "Epoch 20/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 3.9343 - acc: 0.1017 - val_loss: 3.8128 - val_acc: 0.1530\n",
      "Epoch 21/600\n",
      "3491/3491 [==============================] - 1s 294us/step - loss: 3.8925 - acc: 0.1068 - val_loss: 3.7523 - val_acc: 0.1703\n",
      "Epoch 22/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 3.8571 - acc: 0.1152 - val_loss: 3.6923 - val_acc: 0.1931\n",
      "Epoch 23/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 3.8085 - acc: 0.1200 - val_loss: 3.6318 - val_acc: 0.2011\n",
      "Epoch 24/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 3.7334 - acc: 0.1258 - val_loss: 3.5597 - val_acc: 0.2211\n",
      "Epoch 25/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 3.6973 - acc: 0.1329 - val_loss: 3.5172 - val_acc: 0.2398\n",
      "Epoch 26/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 3.6652 - acc: 0.1530 - val_loss: 3.4757 - val_acc: 0.2619\n",
      "Epoch 27/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 3.6037 - acc: 0.1555 - val_loss: 3.4216 - val_acc: 0.2879\n",
      "Epoch 28/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 3.5670 - acc: 0.1547 - val_loss: 3.3425 - val_acc: 0.3160\n",
      "Epoch 29/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 3.5125 - acc: 0.1724 - val_loss: 3.3050 - val_acc: 0.3226\n",
      "Epoch 30/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 3.5061 - acc: 0.1716 - val_loss: 3.2275 - val_acc: 0.3454\n",
      "Epoch 31/600\n",
      "3491/3491 [==============================] - 1s 317us/step - loss: 3.4574 - acc: 0.1808 - val_loss: 3.1822 - val_acc: 0.3647\n",
      "Epoch 32/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 3.3874 - acc: 0.1962 - val_loss: 3.1544 - val_acc: 0.3781\n",
      "Epoch 33/600\n",
      "3491/3491 [==============================] - 1s 292us/step - loss: 3.3577 - acc: 0.1968 - val_loss: 3.1029 - val_acc: 0.3794\n",
      "Epoch 34/600\n",
      "3491/3491 [==============================] - 1s 307us/step - loss: 3.2949 - acc: 0.2180 - val_loss: 3.0463 - val_acc: 0.3961\n",
      "Epoch 35/600\n",
      "3491/3491 [==============================] - 1s 331us/step - loss: 3.2862 - acc: 0.2166 - val_loss: 2.9831 - val_acc: 0.4182\n",
      "Epoch 36/600\n",
      "3491/3491 [==============================] - 1s 337us/step - loss: 3.2524 - acc: 0.2266 - val_loss: 2.9152 - val_acc: 0.4389\n",
      "Epoch 37/600\n",
      "3491/3491 [==============================] - 1s 309us/step - loss: 3.1926 - acc: 0.2246 - val_loss: 2.8918 - val_acc: 0.4415\n",
      "Epoch 38/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 3.1375 - acc: 0.2463 - val_loss: 2.8460 - val_acc: 0.4415\n",
      "Epoch 39/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 3.1088 - acc: 0.2509 - val_loss: 2.7904 - val_acc: 0.4623\n",
      "Epoch 40/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 3.0654 - acc: 0.2647 - val_loss: 2.7503 - val_acc: 0.4676\n",
      "Epoch 41/600\n",
      "3491/3491 [==============================] - 1s 317us/step - loss: 3.0083 - acc: 0.2678 - val_loss: 2.6833 - val_acc: 0.4836\n",
      "Epoch 42/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 2.9728 - acc: 0.2678 - val_loss: 2.6224 - val_acc: 0.4990\n",
      "Epoch 43/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 2.9437 - acc: 0.2801 - val_loss: 2.5886 - val_acc: 0.5023\n",
      "Epoch 44/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 2.8897 - acc: 0.2896 - val_loss: 2.5446 - val_acc: 0.4977\n",
      "Epoch 45/600\n",
      "3491/3491 [==============================] - 1s 322us/step - loss: 2.8753 - acc: 0.3168 - val_loss: 2.4995 - val_acc: 0.5190\n",
      "Epoch 46/600\n",
      "3491/3491 [==============================] - 1s 339us/step - loss: 2.8151 - acc: 0.3088 - val_loss: 2.4575 - val_acc: 0.5210\n",
      "Epoch 47/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 2.7928 - acc: 0.3131 - val_loss: 2.4144 - val_acc: 0.5551\n",
      "Epoch 48/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 2.7661 - acc: 0.3243 - val_loss: 2.3664 - val_acc: 0.5524\n",
      "Epoch 49/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 2.7005 - acc: 0.3334 - val_loss: 2.3239 - val_acc: 0.5718\n",
      "Epoch 50/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 2.6482 - acc: 0.3498 - val_loss: 2.2900 - val_acc: 0.5658\n",
      "Epoch 51/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 2.6548 - acc: 0.3466 - val_loss: 2.2602 - val_acc: 0.5765\n",
      "Epoch 52/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 2.6033 - acc: 0.3469 - val_loss: 2.2245 - val_acc: 0.5818\n",
      "Epoch 53/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 2.5611 - acc: 0.3618 - val_loss: 2.1762 - val_acc: 0.5925\n",
      "Epoch 54/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 2.5077 - acc: 0.3864 - val_loss: 2.1374 - val_acc: 0.5979\n",
      "Epoch 55/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 2.4748 - acc: 0.3830 - val_loss: 2.0976 - val_acc: 0.6186\n",
      "Epoch 56/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 2.4428 - acc: 0.3841 - val_loss: 2.0706 - val_acc: 0.6179\n",
      "Epoch 57/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 2.4293 - acc: 0.3950 - val_loss: 2.0216 - val_acc: 0.6273\n",
      "Epoch 58/600\n",
      "3491/3491 [==============================] - 1s 250us/step - loss: 2.3716 - acc: 0.4208 - val_loss: 1.9806 - val_acc: 0.6393\n",
      "Epoch 59/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 1s 271us/step - loss: 2.3595 - acc: 0.4188 - val_loss: 1.9272 - val_acc: 0.6386\n",
      "Epoch 60/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 2.3346 - acc: 0.4211 - val_loss: 1.9230 - val_acc: 0.6399\n",
      "Epoch 61/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 2.3013 - acc: 0.4314 - val_loss: 1.8715 - val_acc: 0.6480\n",
      "Epoch 62/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 2.2928 - acc: 0.4202 - val_loss: 1.8595 - val_acc: 0.6486\n",
      "Epoch 63/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 2.2592 - acc: 0.4271 - val_loss: 1.8248 - val_acc: 0.6506\n",
      "Epoch 64/600\n",
      "3491/3491 [==============================] - 1s 296us/step - loss: 2.2164 - acc: 0.4529 - val_loss: 1.7880 - val_acc: 0.6540\n",
      "Epoch 65/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 2.1775 - acc: 0.4391 - val_loss: 1.7669 - val_acc: 0.6640\n",
      "Epoch 66/600\n",
      "3491/3491 [==============================] - 1s 310us/step - loss: 2.1850 - acc: 0.4537 - val_loss: 1.7351 - val_acc: 0.6593\n",
      "Epoch 67/600\n",
      "3491/3491 [==============================] - 1s 306us/step - loss: 2.1451 - acc: 0.4692 - val_loss: 1.7132 - val_acc: 0.6667\n",
      "Epoch 68/600\n",
      "3491/3491 [==============================] - 1s 306us/step - loss: 2.0795 - acc: 0.4675 - val_loss: 1.6915 - val_acc: 0.6733\n",
      "Epoch 69/600\n",
      "3491/3491 [==============================] - 1s 296us/step - loss: 2.0780 - acc: 0.4701 - val_loss: 1.6523 - val_acc: 0.6720\n",
      "Epoch 70/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 2.0763 - acc: 0.4704 - val_loss: 1.6331 - val_acc: 0.6800\n",
      "Epoch 71/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 2.0307 - acc: 0.4812 - val_loss: 1.6318 - val_acc: 0.6780\n",
      "Epoch 72/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 1.9859 - acc: 0.4993 - val_loss: 1.5821 - val_acc: 0.6867\n",
      "Epoch 73/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 1.9679 - acc: 0.5039 - val_loss: 1.5576 - val_acc: 0.6847\n",
      "Epoch 74/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 1.9521 - acc: 0.5010 - val_loss: 1.5378 - val_acc: 0.6900\n",
      "Epoch 75/600\n",
      "3491/3491 [==============================] - 1s 288us/step - loss: 1.9603 - acc: 0.4999 - val_loss: 1.5070 - val_acc: 0.6947\n",
      "Epoch 76/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 1.9377 - acc: 0.5044 - val_loss: 1.4836 - val_acc: 0.6967\n",
      "Epoch 77/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 1.8965 - acc: 0.5182 - val_loss: 1.4691 - val_acc: 0.7041\n",
      "Epoch 78/600\n",
      "3491/3491 [==============================] - 1s 301us/step - loss: 1.8962 - acc: 0.5153 - val_loss: 1.4559 - val_acc: 0.7088\n",
      "Epoch 79/600\n",
      "3491/3491 [==============================] - 1s 328us/step - loss: 1.8583 - acc: 0.5205 - val_loss: 1.4418 - val_acc: 0.7074\n",
      "Epoch 80/600\n",
      "3491/3491 [==============================] - 1s 334us/step - loss: 1.8481 - acc: 0.5242 - val_loss: 1.4193 - val_acc: 0.7141\n",
      "Epoch 81/600\n",
      "3491/3491 [==============================] - 1s 292us/step - loss: 1.8217 - acc: 0.5420 - val_loss: 1.3944 - val_acc: 0.7108\n",
      "Epoch 82/600\n",
      "3491/3491 [==============================] - 1s 325us/step - loss: 1.8085 - acc: 0.5397 - val_loss: 1.3684 - val_acc: 0.7181\n",
      "Epoch 83/600\n",
      "3491/3491 [==============================] - 1s 292us/step - loss: 1.7872 - acc: 0.5443 - val_loss: 1.3657 - val_acc: 0.7174\n",
      "Epoch 84/600\n",
      "3491/3491 [==============================] - 1s 312us/step - loss: 1.7283 - acc: 0.5600 - val_loss: 1.3423 - val_acc: 0.7295\n",
      "Epoch 85/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 1.7202 - acc: 0.5491 - val_loss: 1.3265 - val_acc: 0.7261\n",
      "Epoch 86/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 1.7245 - acc: 0.5580 - val_loss: 1.3031 - val_acc: 0.7288\n",
      "Epoch 87/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 1.7190 - acc: 0.5666 - val_loss: 1.2940 - val_acc: 0.7341\n",
      "Epoch 88/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 1.6496 - acc: 0.5657 - val_loss: 1.2659 - val_acc: 0.7368\n",
      "Epoch 89/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 1.6853 - acc: 0.5529 - val_loss: 1.2519 - val_acc: 0.7381\n",
      "Epoch 90/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 1.6350 - acc: 0.5898 - val_loss: 1.2416 - val_acc: 0.7515\n",
      "Epoch 91/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 1.6194 - acc: 0.5838 - val_loss: 1.2250 - val_acc: 0.7462\n",
      "Epoch 92/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 1.6201 - acc: 0.5832 - val_loss: 1.2173 - val_acc: 0.7435\n",
      "Epoch 93/600\n",
      "3491/3491 [==============================] - 1s 283us/step - loss: 1.5833 - acc: 0.5907 - val_loss: 1.2023 - val_acc: 0.7508\n",
      "Epoch 94/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 1.6128 - acc: 0.5852 - val_loss: 1.1864 - val_acc: 0.7455\n",
      "Epoch 95/600\n",
      "3491/3491 [==============================] - 1s 276us/step - loss: 1.6001 - acc: 0.5867 - val_loss: 1.1726 - val_acc: 0.7568\n",
      "Epoch 96/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 1.5918 - acc: 0.5970 - val_loss: 1.1645 - val_acc: 0.7582\n",
      "Epoch 97/600\n",
      "3491/3491 [==============================] - 1s 323us/step - loss: 1.5342 - acc: 0.6056 - val_loss: 1.1381 - val_acc: 0.7669\n",
      "Epoch 98/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 1.5201 - acc: 0.6130 - val_loss: 1.1431 - val_acc: 0.7629\n",
      "Epoch 99/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 1.5065 - acc: 0.6073 - val_loss: 1.1245 - val_acc: 0.7655\n",
      "Epoch 100/600\n",
      "3491/3491 [==============================] - 1s 289us/step - loss: 1.4968 - acc: 0.6104 - val_loss: 1.1135 - val_acc: 0.7669\n",
      "Epoch 101/600\n",
      "3491/3491 [==============================] - 1s 283us/step - loss: 1.4731 - acc: 0.6199 - val_loss: 1.0931 - val_acc: 0.7695\n",
      "Epoch 102/600\n",
      "3491/3491 [==============================] - 1s 288us/step - loss: 1.4592 - acc: 0.6236 - val_loss: 1.0837 - val_acc: 0.7729\n",
      "Epoch 103/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 1.4636 - acc: 0.6250 - val_loss: 1.0779 - val_acc: 0.7722\n",
      "Epoch 104/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 1.4406 - acc: 0.6290 - val_loss: 1.0695 - val_acc: 0.7682\n",
      "Epoch 105/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 1.4051 - acc: 0.6391 - val_loss: 1.0496 - val_acc: 0.7836\n",
      "Epoch 106/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 1.4004 - acc: 0.6365 - val_loss: 1.0395 - val_acc: 0.7776\n",
      "Epoch 107/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 1.4110 - acc: 0.6328 - val_loss: 1.0207 - val_acc: 0.7869\n",
      "Epoch 108/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 1.3827 - acc: 0.6488 - val_loss: 1.0171 - val_acc: 0.7809\n",
      "Epoch 109/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 1.3708 - acc: 0.6382 - val_loss: 1.0020 - val_acc: 0.7923\n",
      "Epoch 110/600\n",
      "3491/3491 [==============================] - 1s 287us/step - loss: 1.3924 - acc: 0.6399 - val_loss: 1.0094 - val_acc: 0.7916\n",
      "Epoch 111/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 1.3389 - acc: 0.6454 - val_loss: 0.9815 - val_acc: 0.7889\n",
      "Epoch 112/600\n",
      "3491/3491 [==============================] - 1s 283us/step - loss: 1.3727 - acc: 0.6511 - val_loss: 0.9802 - val_acc: 0.7849\n",
      "Epoch 113/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 1.3182 - acc: 0.6597 - val_loss: 0.9662 - val_acc: 0.7923\n",
      "Epoch 114/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 1.3254 - acc: 0.6608 - val_loss: 0.9569 - val_acc: 0.7923\n",
      "Epoch 115/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 1.2862 - acc: 0.6606 - val_loss: 0.9451 - val_acc: 0.7969\n",
      "Epoch 116/600\n",
      "3491/3491 [==============================] - 1s 277us/step - loss: 1.3199 - acc: 0.6551 - val_loss: 0.9404 - val_acc: 0.7923\n",
      "Epoch 117/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 1.3062 - acc: 0.6545 - val_loss: 0.9404 - val_acc: 0.7943\n",
      "Epoch 118/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 1s 294us/step - loss: 1.2844 - acc: 0.6568 - val_loss: 0.9216 - val_acc: 0.7976\n",
      "Epoch 119/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 1.2792 - acc: 0.6732 - val_loss: 0.9141 - val_acc: 0.7969\n",
      "Epoch 120/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 1.2869 - acc: 0.6586 - val_loss: 0.9040 - val_acc: 0.7996\n",
      "Epoch 121/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 1.2432 - acc: 0.6666 - val_loss: 0.8938 - val_acc: 0.8016\n",
      "Epoch 122/600\n",
      "3491/3491 [==============================] - 1s 283us/step - loss: 1.2568 - acc: 0.6683 - val_loss: 0.8939 - val_acc: 0.8036\n",
      "Epoch 123/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 1.2604 - acc: 0.6623 - val_loss: 0.8797 - val_acc: 0.8036\n",
      "Epoch 124/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 1.2319 - acc: 0.6743 - val_loss: 0.8767 - val_acc: 0.8049\n",
      "Epoch 125/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 1.1951 - acc: 0.6901 - val_loss: 0.8664 - val_acc: 0.8029\n",
      "Epoch 126/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 1.2122 - acc: 0.6823 - val_loss: 0.8599 - val_acc: 0.8090\n",
      "Epoch 127/600\n",
      "3491/3491 [==============================] - 1s 345us/step - loss: 1.2276 - acc: 0.6746 - val_loss: 0.8526 - val_acc: 0.8090\n",
      "Epoch 128/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 1.1831 - acc: 0.6872 - val_loss: 0.8502 - val_acc: 0.8069\n",
      "Epoch 129/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 1.1937 - acc: 0.6906 - val_loss: 0.8370 - val_acc: 0.8083\n",
      "Epoch 130/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 1.2022 - acc: 0.6898 - val_loss: 0.8333 - val_acc: 0.8150\n",
      "Epoch 131/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 1.1511 - acc: 0.6929 - val_loss: 0.8265 - val_acc: 0.8103\n",
      "Epoch 132/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 1.1320 - acc: 0.7070 - val_loss: 0.8221 - val_acc: 0.8136\n",
      "Epoch 133/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 1.1534 - acc: 0.6955 - val_loss: 0.8185 - val_acc: 0.8156\n",
      "Epoch 134/600\n",
      "3491/3491 [==============================] - 1s 277us/step - loss: 1.1262 - acc: 0.6995 - val_loss: 0.8096 - val_acc: 0.8170\n",
      "Epoch 135/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 1.1331 - acc: 0.7009 - val_loss: 0.8080 - val_acc: 0.8143\n",
      "Epoch 136/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 1.1267 - acc: 0.7070 - val_loss: 0.8046 - val_acc: 0.8130\n",
      "Epoch 137/600\n",
      "3491/3491 [==============================] - 1s 293us/step - loss: 1.1054 - acc: 0.7058 - val_loss: 0.7984 - val_acc: 0.8116\n",
      "Epoch 138/600\n",
      "3491/3491 [==============================] - 1s 288us/step - loss: 1.0994 - acc: 0.7110 - val_loss: 0.7890 - val_acc: 0.8210\n",
      "Epoch 139/600\n",
      "3491/3491 [==============================] - 1s 299us/step - loss: 1.1524 - acc: 0.6981 - val_loss: 0.7956 - val_acc: 0.8130\n",
      "Epoch 140/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 1.0946 - acc: 0.7095 - val_loss: 0.7788 - val_acc: 0.8190\n",
      "Epoch 141/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 1.0833 - acc: 0.7130 - val_loss: 0.7715 - val_acc: 0.8216\n",
      "Epoch 142/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 1.0697 - acc: 0.7138 - val_loss: 0.7715 - val_acc: 0.8196\n",
      "Epoch 143/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 1.0599 - acc: 0.7144 - val_loss: 0.7711 - val_acc: 0.8203\n",
      "Epoch 144/600\n",
      "3491/3491 [==============================] - 1s 287us/step - loss: 1.0286 - acc: 0.7290 - val_loss: 0.7538 - val_acc: 0.8236\n",
      "Epoch 145/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 1.0547 - acc: 0.7210 - val_loss: 0.7478 - val_acc: 0.8216\n",
      "Epoch 146/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 1.0455 - acc: 0.7193 - val_loss: 0.7462 - val_acc: 0.8190\n",
      "Epoch 147/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 1.0546 - acc: 0.7213 - val_loss: 0.7440 - val_acc: 0.8257\n",
      "Epoch 148/600\n",
      "3491/3491 [==============================] - 1s 276us/step - loss: 1.0213 - acc: 0.7267 - val_loss: 0.7355 - val_acc: 0.8243\n",
      "Epoch 149/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 1.0129 - acc: 0.7256 - val_loss: 0.7322 - val_acc: 0.8283\n",
      "Epoch 150/600\n",
      "3491/3491 [==============================] - 1s 373us/step - loss: 1.0240 - acc: 0.7293 - val_loss: 0.7275 - val_acc: 0.8236\n",
      "Epoch 151/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 1.0224 - acc: 0.7219 - val_loss: 0.7185 - val_acc: 0.8270\n",
      "Epoch 152/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 1.0130 - acc: 0.7241 - val_loss: 0.7222 - val_acc: 0.8223\n",
      "Epoch 153/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 1.0277 - acc: 0.7284 - val_loss: 0.7171 - val_acc: 0.8263\n",
      "Epoch 154/600\n",
      "3491/3491 [==============================] - 1s 255us/step - loss: 0.9855 - acc: 0.7304 - val_loss: 0.7096 - val_acc: 0.8290\n",
      "Epoch 155/600\n",
      "3491/3491 [==============================] - 1s 252us/step - loss: 0.9815 - acc: 0.7485 - val_loss: 0.7005 - val_acc: 0.8337\n",
      "Epoch 156/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.9931 - acc: 0.7379 - val_loss: 0.7017 - val_acc: 0.8290\n",
      "Epoch 157/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.9866 - acc: 0.7419 - val_loss: 0.6980 - val_acc: 0.8350\n",
      "Epoch 158/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 0.9864 - acc: 0.7365 - val_loss: 0.6977 - val_acc: 0.8350\n",
      "Epoch 159/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 0.9785 - acc: 0.7368 - val_loss: 0.6877 - val_acc: 0.8323\n",
      "Epoch 160/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 0.9770 - acc: 0.7482 - val_loss: 0.6880 - val_acc: 0.8323\n",
      "Epoch 161/600\n",
      "3491/3491 [==============================] - 1s 277us/step - loss: 0.9448 - acc: 0.7505 - val_loss: 0.6723 - val_acc: 0.8390\n",
      "Epoch 162/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 0.9429 - acc: 0.7425 - val_loss: 0.6717 - val_acc: 0.8377\n",
      "Epoch 163/600\n",
      "3491/3491 [==============================] - 1s 249us/step - loss: 0.9100 - acc: 0.7479 - val_loss: 0.6669 - val_acc: 0.8403\n",
      "Epoch 164/600\n",
      "3491/3491 [==============================] - 1s 251us/step - loss: 0.9513 - acc: 0.7439 - val_loss: 0.6610 - val_acc: 0.8377\n",
      "Epoch 165/600\n",
      "3491/3491 [==============================] - 1s 253us/step - loss: 0.9314 - acc: 0.7511 - val_loss: 0.6610 - val_acc: 0.8370\n",
      "Epoch 166/600\n",
      "3491/3491 [==============================] - 1s 250us/step - loss: 0.9065 - acc: 0.7548 - val_loss: 0.6591 - val_acc: 0.8377\n",
      "Epoch 167/600\n",
      "3491/3491 [==============================] - 1s 250us/step - loss: 0.9214 - acc: 0.7537 - val_loss: 0.6505 - val_acc: 0.8397\n",
      "Epoch 168/600\n",
      "3491/3491 [==============================] - 1s 249us/step - loss: 0.9225 - acc: 0.7528 - val_loss: 0.6610 - val_acc: 0.8430\n",
      "Epoch 169/600\n",
      "3491/3491 [==============================] - 1s 247us/step - loss: 0.9271 - acc: 0.7562 - val_loss: 0.6472 - val_acc: 0.8370\n",
      "Epoch 170/600\n",
      "3491/3491 [==============================] - 1s 247us/step - loss: 0.9195 - acc: 0.7491 - val_loss: 0.6455 - val_acc: 0.8397\n",
      "Epoch 171/600\n",
      "3491/3491 [==============================] - 1s 249us/step - loss: 0.9074 - acc: 0.7585 - val_loss: 0.6407 - val_acc: 0.8417\n",
      "Epoch 172/600\n",
      "3491/3491 [==============================] - 1s 247us/step - loss: 0.9055 - acc: 0.7554 - val_loss: 0.6327 - val_acc: 0.8424\n",
      "Epoch 173/600\n",
      "3491/3491 [==============================] - 1s 250us/step - loss: 0.8823 - acc: 0.7528 - val_loss: 0.6288 - val_acc: 0.8464\n",
      "Epoch 174/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.8689 - acc: 0.7660 - val_loss: 0.6232 - val_acc: 0.8437\n",
      "Epoch 175/600\n",
      "3491/3491 [==============================] - 1s 258us/step - loss: 0.8849 - acc: 0.7579 - val_loss: 0.6264 - val_acc: 0.8457\n",
      "Epoch 176/600\n",
      "3491/3491 [==============================] - 1s 258us/step - loss: 0.8737 - acc: 0.7617 - val_loss: 0.6186 - val_acc: 0.8484\n",
      "Epoch 177/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 1s 253us/step - loss: 0.8696 - acc: 0.7608 - val_loss: 0.6385 - val_acc: 0.8497\n",
      "Epoch 178/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 0.8711 - acc: 0.7657 - val_loss: 0.6370 - val_acc: 0.8490\n",
      "Epoch 179/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.8794 - acc: 0.7611 - val_loss: 0.6182 - val_acc: 0.8477\n",
      "Epoch 180/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.8581 - acc: 0.7700 - val_loss: 0.6135 - val_acc: 0.8497\n",
      "Epoch 181/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 0.8431 - acc: 0.7757 - val_loss: 0.6066 - val_acc: 0.8477\n",
      "Epoch 182/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.8743 - acc: 0.7703 - val_loss: 0.6123 - val_acc: 0.8484\n",
      "Epoch 183/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 0.8746 - acc: 0.7625 - val_loss: 0.6086 - val_acc: 0.8524\n",
      "Epoch 184/600\n",
      "3491/3491 [==============================] - 1s 294us/step - loss: 0.8528 - acc: 0.7703 - val_loss: 0.5986 - val_acc: 0.8497\n",
      "Epoch 185/600\n",
      "3491/3491 [==============================] - 1s 312us/step - loss: 0.8313 - acc: 0.7812 - val_loss: 0.5974 - val_acc: 0.8524\n",
      "Epoch 186/600\n",
      "3491/3491 [==============================] - 1s 303us/step - loss: 0.8353 - acc: 0.7823 - val_loss: 0.5907 - val_acc: 0.8544\n",
      "Epoch 187/600\n",
      "3491/3491 [==============================] - 1s 312us/step - loss: 0.8218 - acc: 0.7786 - val_loss: 0.5869 - val_acc: 0.8604\n",
      "Epoch 188/600\n",
      "3491/3491 [==============================] - 1s 289us/step - loss: 0.8322 - acc: 0.7677 - val_loss: 0.5895 - val_acc: 0.8577\n",
      "Epoch 189/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 0.8368 - acc: 0.7683 - val_loss: 0.5776 - val_acc: 0.8597\n",
      "Epoch 190/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.8309 - acc: 0.7800 - val_loss: 0.5805 - val_acc: 0.8564\n",
      "Epoch 191/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.8157 - acc: 0.7809 - val_loss: 0.5873 - val_acc: 0.8530\n",
      "Epoch 192/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.8072 - acc: 0.7794 - val_loss: 0.5792 - val_acc: 0.8577\n",
      "Epoch 193/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.8118 - acc: 0.7803 - val_loss: 0.5725 - val_acc: 0.8604\n",
      "Epoch 194/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.8135 - acc: 0.7849 - val_loss: 0.5812 - val_acc: 0.8570\n",
      "Epoch 195/600\n",
      "3491/3491 [==============================] - 1s 315us/step - loss: 0.8190 - acc: 0.7800 - val_loss: 0.5738 - val_acc: 0.8570\n",
      "Epoch 196/600\n",
      "3491/3491 [==============================] - 1s 312us/step - loss: 0.7846 - acc: 0.7886 - val_loss: 0.5737 - val_acc: 0.8570\n",
      "Epoch 197/600\n",
      "3491/3491 [==============================] - ETA: 0s - loss: 0.7729 - acc: 0.785 - 1s 265us/step - loss: 0.7817 - acc: 0.7826 - val_loss: 0.5639 - val_acc: 0.8584\n",
      "Epoch 198/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.7791 - acc: 0.7875 - val_loss: 0.5626 - val_acc: 0.8624\n",
      "Epoch 199/600\n",
      "3491/3491 [==============================] - 1s 277us/step - loss: 0.8045 - acc: 0.7875 - val_loss: 0.5640 - val_acc: 0.8570\n",
      "Epoch 200/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 0.7865 - acc: 0.7889 - val_loss: 0.5628 - val_acc: 0.8617\n",
      "Epoch 201/600\n",
      "3491/3491 [==============================] - 1s 287us/step - loss: 0.7669 - acc: 0.7875 - val_loss: 0.5531 - val_acc: 0.8637\n",
      "Epoch 202/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.7230 - acc: 0.8107 - val_loss: 0.5731 - val_acc: 0.8617\n",
      "Epoch 203/600\n",
      "3491/3491 [==============================] - 1s 311us/step - loss: 0.7911 - acc: 0.7872 - val_loss: 0.5709 - val_acc: 0.8611\n",
      "Epoch 204/600\n",
      "3491/3491 [==============================] - 1s 327us/step - loss: 0.7751 - acc: 0.7852 - val_loss: 0.5597 - val_acc: 0.8637\n",
      "Epoch 205/600\n",
      "3491/3491 [==============================] - 1s 251us/step - loss: 0.7904 - acc: 0.7823 - val_loss: 0.5610 - val_acc: 0.8644\n",
      "Epoch 206/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.7716 - acc: 0.7938 - val_loss: 0.5578 - val_acc: 0.8664\n",
      "Epoch 207/600\n",
      "3491/3491 [==============================] - 1s 309us/step - loss: 0.7361 - acc: 0.7946 - val_loss: 0.5431 - val_acc: 0.8671\n",
      "Epoch 208/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.7692 - acc: 0.7920 - val_loss: 0.5452 - val_acc: 0.8697\n",
      "Epoch 209/600\n",
      "3491/3491 [==============================] - 1s 295us/step - loss: 0.7562 - acc: 0.7995 - val_loss: 0.5418 - val_acc: 0.8691\n",
      "Epoch 210/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 0.7552 - acc: 0.8044 - val_loss: 0.5507 - val_acc: 0.8637\n",
      "Epoch 211/600\n",
      "3491/3491 [==============================] - 1s 288us/step - loss: 0.7553 - acc: 0.7958 - val_loss: 0.5347 - val_acc: 0.8691\n",
      "Epoch 212/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 0.7372 - acc: 0.7975 - val_loss: 0.5311 - val_acc: 0.8711\n",
      "Epoch 213/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.7580 - acc: 0.7963 - val_loss: 0.5241 - val_acc: 0.8711\n",
      "Epoch 214/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.7260 - acc: 0.8029 - val_loss: 0.5272 - val_acc: 0.8664\n",
      "Epoch 215/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 0.7633 - acc: 0.7900 - val_loss: 0.5291 - val_acc: 0.8711\n",
      "Epoch 216/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 0.7252 - acc: 0.8049 - val_loss: 0.5301 - val_acc: 0.8697\n",
      "Epoch 217/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.7316 - acc: 0.7952 - val_loss: 0.5401 - val_acc: 0.8711\n",
      "Epoch 218/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.7429 - acc: 0.8003 - val_loss: 0.5213 - val_acc: 0.8758\n",
      "Epoch 219/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.7147 - acc: 0.8029 - val_loss: 0.5214 - val_acc: 0.8677\n",
      "Epoch 220/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.7014 - acc: 0.8147 - val_loss: 0.5251 - val_acc: 0.8671\n",
      "Epoch 221/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 0.7004 - acc: 0.8078 - val_loss: 0.5286 - val_acc: 0.8697\n",
      "Epoch 222/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.7126 - acc: 0.8084 - val_loss: 0.5088 - val_acc: 0.8711\n",
      "Epoch 223/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.7152 - acc: 0.8015 - val_loss: 0.5176 - val_acc: 0.8691\n",
      "Epoch 224/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.7177 - acc: 0.8026 - val_loss: 0.5103 - val_acc: 0.8704\n",
      "Epoch 225/600\n",
      "3491/3491 [==============================] - 1s 307us/step - loss: 0.6863 - acc: 0.8158 - val_loss: 0.5123 - val_acc: 0.8717\n",
      "Epoch 226/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.7219 - acc: 0.8041 - val_loss: 0.5072 - val_acc: 0.8751\n",
      "Epoch 227/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.7009 - acc: 0.8044 - val_loss: 0.5081 - val_acc: 0.8778\n",
      "Epoch 228/600\n",
      "3491/3491 [==============================] - 1s 292us/step - loss: 0.7048 - acc: 0.8038 - val_loss: 0.5058 - val_acc: 0.8731\n",
      "Epoch 229/600\n",
      "3491/3491 [==============================] - 1s 353us/step - loss: 0.7043 - acc: 0.8041 - val_loss: 0.5018 - val_acc: 0.8744\n",
      "Epoch 230/600\n",
      "3491/3491 [==============================] - 1s 288us/step - loss: 0.6956 - acc: 0.8135 - val_loss: 0.4996 - val_acc: 0.8811\n",
      "Epoch 231/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 0.7160 - acc: 0.8098 - val_loss: 0.4996 - val_acc: 0.8784\n",
      "Epoch 232/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.6875 - acc: 0.8129 - val_loss: 0.4934 - val_acc: 0.8784\n",
      "Epoch 233/600\n",
      "3491/3491 [==============================] - 1s 252us/step - loss: 0.7009 - acc: 0.8084 - val_loss: 0.5057 - val_acc: 0.8758\n",
      "Epoch 234/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 0.6970 - acc: 0.8069 - val_loss: 0.4929 - val_acc: 0.8798\n",
      "Epoch 235/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.6741 - acc: 0.8141 - val_loss: 0.5041 - val_acc: 0.8771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.6886 - acc: 0.8141 - val_loss: 0.4900 - val_acc: 0.8798\n",
      "Epoch 237/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.6717 - acc: 0.8158 - val_loss: 0.4853 - val_acc: 0.8791\n",
      "Epoch 238/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.6616 - acc: 0.8230 - val_loss: 0.4843 - val_acc: 0.8791\n",
      "Epoch 239/600\n",
      "3491/3491 [==============================] - 1s 256us/step - loss: 0.6574 - acc: 0.8172 - val_loss: 0.4859 - val_acc: 0.8798\n",
      "Epoch 240/600\n",
      "3491/3491 [==============================] - 1s 252us/step - loss: 0.6907 - acc: 0.8046 - val_loss: 0.4820 - val_acc: 0.8844\n",
      "Epoch 241/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.6700 - acc: 0.8121 - val_loss: 0.4915 - val_acc: 0.8798\n",
      "Epoch 242/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 0.6670 - acc: 0.8147 - val_loss: 0.4991 - val_acc: 0.8838\n",
      "Epoch 243/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.6910 - acc: 0.8184 - val_loss: 0.4908 - val_acc: 0.8844\n",
      "Epoch 244/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 0.6838 - acc: 0.8018 - val_loss: 0.4778 - val_acc: 0.8858\n",
      "Epoch 245/600\n",
      "3491/3491 [==============================] - 1s 252us/step - loss: 0.6707 - acc: 0.8178 - val_loss: 0.4746 - val_acc: 0.8824\n",
      "Epoch 246/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.6465 - acc: 0.8195 - val_loss: 0.4731 - val_acc: 0.8871\n",
      "Epoch 247/600\n",
      "3491/3491 [==============================] - 1s 246us/step - loss: 0.6402 - acc: 0.8250 - val_loss: 0.4858 - val_acc: 0.8844\n",
      "Epoch 248/600\n",
      "3491/3491 [==============================] - 1s 247us/step - loss: 0.6761 - acc: 0.8181 - val_loss: 0.4677 - val_acc: 0.8884\n",
      "Epoch 249/600\n",
      "3491/3491 [==============================] - 1s 245us/step - loss: 0.6240 - acc: 0.8195 - val_loss: 0.4707 - val_acc: 0.8851\n",
      "Epoch 250/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.6640 - acc: 0.8192 - val_loss: 0.4789 - val_acc: 0.8858\n",
      "Epoch 251/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 0.6415 - acc: 0.8233 - val_loss: 0.4671 - val_acc: 0.8838\n",
      "Epoch 252/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 0.6534 - acc: 0.8201 - val_loss: 0.4650 - val_acc: 0.8831\n",
      "Epoch 253/600\n",
      "3491/3491 [==============================] - 1s 303us/step - loss: 0.6373 - acc: 0.8261 - val_loss: 0.4654 - val_acc: 0.8864\n",
      "Epoch 254/600\n",
      "3491/3491 [==============================] - 1s 314us/step - loss: 0.6381 - acc: 0.8293 - val_loss: 0.4603 - val_acc: 0.8878\n",
      "Epoch 255/600\n",
      "3491/3491 [==============================] - 1s 363us/step - loss: 0.6382 - acc: 0.8233 - val_loss: 0.4604 - val_acc: 0.8864\n",
      "Epoch 256/600\n",
      "3491/3491 [==============================] - 1s 382us/step - loss: 0.6398 - acc: 0.8218 - val_loss: 0.4661 - val_acc: 0.8858\n",
      "Epoch 257/600\n",
      "3491/3491 [==============================] - 1s 389us/step - loss: 0.6360 - acc: 0.8247 - val_loss: 0.4586 - val_acc: 0.8884\n",
      "Epoch 258/600\n",
      "3491/3491 [==============================] - 1s 390us/step - loss: 0.6177 - acc: 0.8321 - val_loss: 0.4561 - val_acc: 0.8864\n",
      "Epoch 259/600\n",
      "3491/3491 [==============================] - 1s 419us/step - loss: 0.6193 - acc: 0.8256 - val_loss: 0.4595 - val_acc: 0.8871\n",
      "Epoch 260/600\n",
      "3491/3491 [==============================] - 1s 337us/step - loss: 0.6272 - acc: 0.8344 - val_loss: 0.4638 - val_acc: 0.8878\n",
      "Epoch 261/600\n",
      "3491/3491 [==============================] - 1s 341us/step - loss: 0.6141 - acc: 0.8233 - val_loss: 0.4605 - val_acc: 0.8884\n",
      "Epoch 262/600\n",
      "3491/3491 [==============================] - 1s 333us/step - loss: 0.6279 - acc: 0.8230 - val_loss: 0.4585 - val_acc: 0.8851\n",
      "Epoch 263/600\n",
      "3491/3491 [==============================] - 1s 345us/step - loss: 0.5981 - acc: 0.8313 - val_loss: 0.4546 - val_acc: 0.8871\n",
      "Epoch 264/600\n",
      "3491/3491 [==============================] - 1s 402us/step - loss: 0.5921 - acc: 0.8333 - val_loss: 0.4545 - val_acc: 0.8871\n",
      "Epoch 265/600\n",
      "3491/3491 [==============================] - 1s 419us/step - loss: 0.6039 - acc: 0.8341 - val_loss: 0.4463 - val_acc: 0.8891\n",
      "Epoch 266/600\n",
      "3491/3491 [==============================] - 1s 366us/step - loss: 0.6147 - acc: 0.8301 - val_loss: 0.4542 - val_acc: 0.8878\n",
      "Epoch 267/600\n",
      "3491/3491 [==============================] - 1s 368us/step - loss: 0.6087 - acc: 0.8364 - val_loss: 0.4471 - val_acc: 0.8931\n",
      "Epoch 268/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 0.6205 - acc: 0.8296 - val_loss: 0.4460 - val_acc: 0.8884\n",
      "Epoch 269/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.6095 - acc: 0.8330 - val_loss: 0.4438 - val_acc: 0.8925\n",
      "Epoch 270/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.6023 - acc: 0.8344 - val_loss: 0.4388 - val_acc: 0.8918\n",
      "Epoch 271/600\n",
      "3491/3491 [==============================] - 1s 276us/step - loss: 0.6100 - acc: 0.8330 - val_loss: 0.4497 - val_acc: 0.8911\n",
      "Epoch 272/600\n",
      "3491/3491 [==============================] - 1s 289us/step - loss: 0.6012 - acc: 0.8333 - val_loss: 0.4448 - val_acc: 0.8911\n",
      "Epoch 273/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 0.6050 - acc: 0.8359 - val_loss: 0.4420 - val_acc: 0.8951\n",
      "Epoch 274/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.5905 - acc: 0.8367 - val_loss: 0.4375 - val_acc: 0.8965\n",
      "Epoch 275/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 0.6115 - acc: 0.8362 - val_loss: 0.4418 - val_acc: 0.8951\n",
      "Epoch 276/600\n",
      "3491/3491 [==============================] - 1s 303us/step - loss: 0.5740 - acc: 0.8479 - val_loss: 0.4314 - val_acc: 0.8951\n",
      "Epoch 277/600\n",
      "3491/3491 [==============================] - 1s 327us/step - loss: 0.5975 - acc: 0.8359 - val_loss: 0.4364 - val_acc: 0.8911\n",
      "Epoch 278/600\n",
      "3491/3491 [==============================] - 1s 327us/step - loss: 0.6094 - acc: 0.8298 - val_loss: 0.4313 - val_acc: 0.8978\n",
      "Epoch 279/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 0.5934 - acc: 0.8382 - val_loss: 0.4288 - val_acc: 0.8978\n",
      "Epoch 280/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.5998 - acc: 0.8387 - val_loss: 0.4427 - val_acc: 0.8998\n",
      "Epoch 281/600\n",
      "3491/3491 [==============================] - 1s 316us/step - loss: 0.5852 - acc: 0.8399 - val_loss: 0.4280 - val_acc: 0.8958\n",
      "Epoch 282/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 0.5783 - acc: 0.8362 - val_loss: 0.4291 - val_acc: 0.8945\n",
      "Epoch 283/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.5809 - acc: 0.8393 - val_loss: 0.4305 - val_acc: 0.8958\n",
      "Epoch 284/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 0.5815 - acc: 0.8399 - val_loss: 0.4251 - val_acc: 0.8965\n",
      "Epoch 285/600\n",
      "3491/3491 [==============================] - 1s 303us/step - loss: 0.6035 - acc: 0.8258 - val_loss: 0.4315 - val_acc: 0.8998\n",
      "Epoch 286/600\n",
      "3491/3491 [==============================] - 1s 294us/step - loss: 0.5869 - acc: 0.8356 - val_loss: 0.4240 - val_acc: 0.8971\n",
      "Epoch 287/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 0.5820 - acc: 0.8350 - val_loss: 0.4262 - val_acc: 0.8971\n",
      "Epoch 288/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.5734 - acc: 0.8413 - val_loss: 0.4411 - val_acc: 0.8965\n",
      "Epoch 289/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.5761 - acc: 0.8327 - val_loss: 0.4251 - val_acc: 0.8985\n",
      "Epoch 290/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 0.5662 - acc: 0.8490 - val_loss: 0.4174 - val_acc: 0.8958\n",
      "Epoch 291/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.5479 - acc: 0.8407 - val_loss: 0.4227 - val_acc: 0.8971\n",
      "Epoch 292/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 0.5719 - acc: 0.8482 - val_loss: 0.4206 - val_acc: 0.8991\n",
      "Epoch 293/600\n",
      "3491/3491 [==============================] - 1s 312us/step - loss: 0.5674 - acc: 0.8462 - val_loss: 0.4163 - val_acc: 0.9005\n",
      "Epoch 294/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.5727 - acc: 0.8390 - val_loss: 0.4191 - val_acc: 0.8965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 0.5805 - acc: 0.8430 - val_loss: 0.4285 - val_acc: 0.8965\n",
      "Epoch 296/600\n",
      "3491/3491 [==============================] - 1s 287us/step - loss: 0.5673 - acc: 0.8436 - val_loss: 0.4279 - val_acc: 0.8985\n",
      "Epoch 297/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.5588 - acc: 0.8476 - val_loss: 0.4107 - val_acc: 0.9031\n",
      "Epoch 298/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 0.5738 - acc: 0.8427 - val_loss: 0.4248 - val_acc: 0.8991\n",
      "Epoch 299/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.5564 - acc: 0.8465 - val_loss: 0.4205 - val_acc: 0.9005\n",
      "Epoch 300/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.5585 - acc: 0.8496 - val_loss: 0.4111 - val_acc: 0.8998\n",
      "Epoch 301/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 0.5381 - acc: 0.8459 - val_loss: 0.4072 - val_acc: 0.8991\n",
      "Epoch 302/600\n",
      "3491/3491 [==============================] - 1s 307us/step - loss: 0.5481 - acc: 0.8473 - val_loss: 0.4079 - val_acc: 0.8998\n",
      "Epoch 303/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 0.5632 - acc: 0.8407 - val_loss: 0.4269 - val_acc: 0.8991\n",
      "Epoch 304/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.5525 - acc: 0.8533 - val_loss: 0.4086 - val_acc: 0.9038\n",
      "Epoch 305/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 0.5540 - acc: 0.8396 - val_loss: 0.4134 - val_acc: 0.9011\n",
      "Epoch 306/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.5650 - acc: 0.8393 - val_loss: 0.4130 - val_acc: 0.8985\n",
      "Epoch 307/600\n",
      "3491/3491 [==============================] - 1s 253us/step - loss: 0.5472 - acc: 0.8516 - val_loss: 0.4064 - val_acc: 0.8991\n",
      "Epoch 308/600\n",
      "3491/3491 [==============================] - 1s 253us/step - loss: 0.5540 - acc: 0.8539 - val_loss: 0.4044 - val_acc: 0.8991\n",
      "Epoch 309/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.5567 - acc: 0.8433 - val_loss: 0.4037 - val_acc: 0.9031\n",
      "Epoch 310/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.5362 - acc: 0.8508 - val_loss: 0.4015 - val_acc: 0.9011\n",
      "Epoch 311/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.5377 - acc: 0.8447 - val_loss: 0.4038 - val_acc: 0.9011\n",
      "Epoch 312/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.5268 - acc: 0.8545 - val_loss: 0.3960 - val_acc: 0.9011\n",
      "Epoch 313/600\n",
      "3491/3491 [==============================] - 1s 258us/step - loss: 0.5549 - acc: 0.8450 - val_loss: 0.3993 - val_acc: 0.9031\n",
      "Epoch 314/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.5331 - acc: 0.8496 - val_loss: 0.4012 - val_acc: 0.9065\n",
      "Epoch 315/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.5427 - acc: 0.8470 - val_loss: 0.3979 - val_acc: 0.9051\n",
      "Epoch 316/600\n",
      "3491/3491 [==============================] - 1s 256us/step - loss: 0.5165 - acc: 0.8559 - val_loss: 0.4092 - val_acc: 0.9005\n",
      "Epoch 317/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 0.5280 - acc: 0.8519 - val_loss: 0.4101 - val_acc: 0.9025\n",
      "Epoch 318/600\n",
      "3491/3491 [==============================] - 1s 345us/step - loss: 0.5511 - acc: 0.8479 - val_loss: 0.4002 - val_acc: 0.9025\n",
      "Epoch 319/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.5022 - acc: 0.8631 - val_loss: 0.4013 - val_acc: 0.9018\n",
      "Epoch 320/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 0.5223 - acc: 0.8556 - val_loss: 0.4036 - val_acc: 0.9078\n",
      "Epoch 321/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.5262 - acc: 0.8591 - val_loss: 0.3939 - val_acc: 0.9038\n",
      "Epoch 322/600\n",
      "3491/3491 [==============================] - 1s 361us/step - loss: 0.5026 - acc: 0.8599 - val_loss: 0.3961 - val_acc: 0.9051\n",
      "Epoch 323/600\n",
      "3491/3491 [==============================] - 1s 296us/step - loss: 0.5179 - acc: 0.8516 - val_loss: 0.3972 - val_acc: 0.9038\n",
      "Epoch 324/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 0.5254 - acc: 0.8585 - val_loss: 0.4090 - val_acc: 0.9051\n",
      "Epoch 325/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.5255 - acc: 0.8513 - val_loss: 0.3884 - val_acc: 0.9071\n",
      "Epoch 326/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.5161 - acc: 0.8559 - val_loss: 0.3901 - val_acc: 0.9051\n",
      "Epoch 327/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 0.4996 - acc: 0.8542 - val_loss: 0.3909 - val_acc: 0.9085\n",
      "Epoch 328/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 0.5121 - acc: 0.8582 - val_loss: 0.3949 - val_acc: 0.9092\n",
      "Epoch 329/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.4930 - acc: 0.8694 - val_loss: 0.3925 - val_acc: 0.9051\n",
      "Epoch 330/600\n",
      "3491/3491 [==============================] - 1s 321us/step - loss: 0.5078 - acc: 0.8591 - val_loss: 0.3930 - val_acc: 0.9065\n",
      "Epoch 331/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 0.5155 - acc: 0.8571 - val_loss: 0.3966 - val_acc: 0.9058\n",
      "Epoch 332/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 0.4908 - acc: 0.8628 - val_loss: 0.3962 - val_acc: 0.9045\n",
      "Epoch 333/600\n",
      "3491/3491 [==============================] - 1s 314us/step - loss: 0.5086 - acc: 0.8602 - val_loss: 0.3807 - val_acc: 0.9071\n",
      "Epoch 334/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 0.5141 - acc: 0.8596 - val_loss: 0.3875 - val_acc: 0.9051\n",
      "Epoch 335/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 0.5128 - acc: 0.8568 - val_loss: 0.3742 - val_acc: 0.9078\n",
      "Epoch 336/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.5152 - acc: 0.8556 - val_loss: 0.3821 - val_acc: 0.9071\n",
      "Epoch 337/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 0.5144 - acc: 0.8579 - val_loss: 0.3817 - val_acc: 0.9092\n",
      "Epoch 338/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.4812 - acc: 0.8634 - val_loss: 0.3908 - val_acc: 0.9071\n",
      "Epoch 339/600\n",
      "3491/3491 [==============================] - 1s 322us/step - loss: 0.4941 - acc: 0.8551 - val_loss: 0.3810 - val_acc: 0.9078\n",
      "Epoch 340/600\n",
      "3491/3491 [==============================] - 1s 375us/step - loss: 0.5061 - acc: 0.8625 - val_loss: 0.3886 - val_acc: 0.9065\n",
      "Epoch 341/600\n",
      "3491/3491 [==============================] - 1s 306us/step - loss: 0.4992 - acc: 0.8573 - val_loss: 0.3771 - val_acc: 0.9098\n",
      "Epoch 342/600\n",
      "3491/3491 [==============================] - 1s 322us/step - loss: 0.4992 - acc: 0.8642 - val_loss: 0.3837 - val_acc: 0.9078\n",
      "Epoch 343/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 0.5005 - acc: 0.8605 - val_loss: 0.3638 - val_acc: 0.9092\n",
      "Epoch 344/600\n",
      "3491/3491 [==============================] - 1s 334us/step - loss: 0.5159 - acc: 0.8531 - val_loss: 0.3740 - val_acc: 0.9045\n",
      "Epoch 345/600\n",
      "3491/3491 [==============================] - 1s 326us/step - loss: 0.5116 - acc: 0.8614 - val_loss: 0.3667 - val_acc: 0.9051\n",
      "Epoch 346/600\n",
      "3491/3491 [==============================] - 1s 322us/step - loss: 0.5047 - acc: 0.8605 - val_loss: 0.3755 - val_acc: 0.9031\n",
      "Epoch 347/600\n",
      "3491/3491 [==============================] - 1s 311us/step - loss: 0.5089 - acc: 0.8625 - val_loss: 0.3811 - val_acc: 0.9085\n",
      "Epoch 348/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.4970 - acc: 0.8642 - val_loss: 0.3803 - val_acc: 0.9098\n",
      "Epoch 349/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.5101 - acc: 0.8533 - val_loss: 0.3709 - val_acc: 0.9025\n",
      "Epoch 350/600\n",
      "3491/3491 [==============================] - 1s 364us/step - loss: 0.5086 - acc: 0.8594 - val_loss: 0.3732 - val_acc: 0.9092\n",
      "Epoch 351/600\n",
      "3491/3491 [==============================] - 1s 338us/step - loss: 0.4896 - acc: 0.8634 - val_loss: 0.3793 - val_acc: 0.9125\n",
      "Epoch 352/600\n",
      "3491/3491 [==============================] - 1s 370us/step - loss: 0.5039 - acc: 0.8594 - val_loss: 0.3817 - val_acc: 0.9118\n",
      "Epoch 353/600\n",
      "3491/3491 [==============================] - 1s 381us/step - loss: 0.4869 - acc: 0.8674 - val_loss: 0.3688 - val_acc: 0.9112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/600\n",
      "3491/3491 [==============================] - 1s 306us/step - loss: 0.4846 - acc: 0.8639 - val_loss: 0.3737 - val_acc: 0.9098\n",
      "Epoch 355/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.4857 - acc: 0.8614 - val_loss: 0.3688 - val_acc: 0.9085\n",
      "Epoch 356/600\n",
      "3491/3491 [==============================] - 1s 293us/step - loss: 0.4842 - acc: 0.8625 - val_loss: 0.3767 - val_acc: 0.9125\n",
      "Epoch 357/600\n",
      "3491/3491 [==============================] - 1s 308us/step - loss: 0.4756 - acc: 0.8628 - val_loss: 0.3612 - val_acc: 0.9098\n",
      "Epoch 358/600\n",
      "3491/3491 [==============================] - 1s 309us/step - loss: 0.4662 - acc: 0.8651 - val_loss: 0.3622 - val_acc: 0.9092\n",
      "Epoch 359/600\n",
      "3491/3491 [==============================] - 1s 304us/step - loss: 0.4608 - acc: 0.8742 - val_loss: 0.3644 - val_acc: 0.9118\n",
      "Epoch 360/600\n",
      "3491/3491 [==============================] - 1s 310us/step - loss: 0.4945 - acc: 0.8651 - val_loss: 0.3674 - val_acc: 0.9098\n",
      "Epoch 361/600\n",
      "3491/3491 [==============================] - 1s 319us/step - loss: 0.4915 - acc: 0.8677 - val_loss: 0.3630 - val_acc: 0.9112\n",
      "Epoch 362/600\n",
      "3491/3491 [==============================] - 1s 363us/step - loss: 0.4787 - acc: 0.8654 - val_loss: 0.3580 - val_acc: 0.9105\n",
      "Epoch 363/600\n",
      "3491/3491 [==============================] - 1s 377us/step - loss: 0.4835 - acc: 0.8691 - val_loss: 0.3665 - val_acc: 0.9112\n",
      "Epoch 364/600\n",
      "3491/3491 [==============================] - 1s 385us/step - loss: 0.4926 - acc: 0.8594 - val_loss: 0.3680 - val_acc: 0.9125\n",
      "Epoch 365/600\n",
      "3491/3491 [==============================] - 1s 367us/step - loss: 0.4749 - acc: 0.8685 - val_loss: 0.3683 - val_acc: 0.9105\n",
      "Epoch 366/600\n",
      "3491/3491 [==============================] - 1s 340us/step - loss: 0.4923 - acc: 0.8608 - val_loss: 0.3691 - val_acc: 0.9098\n",
      "Epoch 367/600\n",
      "3491/3491 [==============================] - 1s 332us/step - loss: 0.4851 - acc: 0.8639 - val_loss: 0.3572 - val_acc: 0.9125\n",
      "Epoch 368/600\n",
      "3491/3491 [==============================] - 1s 307us/step - loss: 0.4848 - acc: 0.8642 - val_loss: 0.3633 - val_acc: 0.9145\n",
      "Epoch 369/600\n",
      "3491/3491 [==============================] - 1s 339us/step - loss: 0.4836 - acc: 0.8714 - val_loss: 0.3576 - val_acc: 0.9125\n",
      "Epoch 370/600\n",
      "3491/3491 [==============================] - 1s 307us/step - loss: 0.4767 - acc: 0.8648 - val_loss: 0.3547 - val_acc: 0.9105\n",
      "Epoch 371/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 0.4804 - acc: 0.8596 - val_loss: 0.3597 - val_acc: 0.9125\n",
      "Epoch 372/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 0.4670 - acc: 0.8657 - val_loss: 0.3577 - val_acc: 0.9132\n",
      "Epoch 373/600\n",
      "3491/3491 [==============================] - 1s 277us/step - loss: 0.4789 - acc: 0.8631 - val_loss: 0.3561 - val_acc: 0.9132\n",
      "Epoch 374/600\n",
      "3491/3491 [==============================] - 1s 383us/step - loss: 0.4654 - acc: 0.8679 - val_loss: 0.3661 - val_acc: 0.9125\n",
      "Epoch 375/600\n",
      "3491/3491 [==============================] - ETA: 0s - loss: 0.4746 - acc: 0.866 - 1s 392us/step - loss: 0.4736 - acc: 0.8651 - val_loss: 0.3587 - val_acc: 0.9092\n",
      "Epoch 376/600\n",
      "3491/3491 [==============================] - 1s 399us/step - loss: 0.4718 - acc: 0.8697 - val_loss: 0.3599 - val_acc: 0.9145\n",
      "Epoch 377/600\n",
      "3491/3491 [==============================] - 1s 345us/step - loss: 0.4581 - acc: 0.8731 - val_loss: 0.3501 - val_acc: 0.9105\n",
      "Epoch 378/600\n",
      "3491/3491 [==============================] - 1s 323us/step - loss: 0.4492 - acc: 0.8685 - val_loss: 0.3648 - val_acc: 0.9112\n",
      "Epoch 379/600\n",
      "3491/3491 [==============================] - 1s 284us/step - loss: 0.4645 - acc: 0.8728 - val_loss: 0.3620 - val_acc: 0.9132\n",
      "Epoch 380/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.4738 - acc: 0.8668 - val_loss: 0.3589 - val_acc: 0.9105\n",
      "Epoch 381/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.4692 - acc: 0.8668 - val_loss: 0.3550 - val_acc: 0.9125\n",
      "Epoch 382/600\n",
      "3491/3491 [==============================] - 1s 293us/step - loss: 0.4507 - acc: 0.8751 - val_loss: 0.3546 - val_acc: 0.9118\n",
      "Epoch 383/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 0.4619 - acc: 0.8742 - val_loss: 0.3521 - val_acc: 0.9138\n",
      "Epoch 384/600\n",
      "3491/3491 [==============================] - 1s 283us/step - loss: 0.4810 - acc: 0.8691 - val_loss: 0.3582 - val_acc: 0.9125\n",
      "Epoch 385/600\n",
      "3491/3491 [==============================] - 1s 315us/step - loss: 0.4604 - acc: 0.8717 - val_loss: 0.3407 - val_acc: 0.9145\n",
      "Epoch 386/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.4759 - acc: 0.8639 - val_loss: 0.3508 - val_acc: 0.9165\n",
      "Epoch 387/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 0.4603 - acc: 0.8757 - val_loss: 0.3556 - val_acc: 0.9132\n",
      "Epoch 388/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 0.4791 - acc: 0.8725 - val_loss: 0.3523 - val_acc: 0.9132\n",
      "Epoch 389/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.4432 - acc: 0.8728 - val_loss: 0.3478 - val_acc: 0.9165\n",
      "Epoch 390/600\n",
      "3491/3491 [==============================] - 1s 258us/step - loss: 0.4601 - acc: 0.8708 - val_loss: 0.3658 - val_acc: 0.9105\n",
      "Epoch 391/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.4605 - acc: 0.8722 - val_loss: 0.3434 - val_acc: 0.9105\n",
      "Epoch 392/600\n",
      "3491/3491 [==============================] - 1s 276us/step - loss: 0.4398 - acc: 0.8803 - val_loss: 0.3452 - val_acc: 0.9152\n",
      "Epoch 393/600\n",
      "3491/3491 [==============================] - 1s 303us/step - loss: 0.4542 - acc: 0.8714 - val_loss: 0.3455 - val_acc: 0.9158\n",
      "Epoch 394/600\n",
      "3491/3491 [==============================] - 1s 356us/step - loss: 0.4616 - acc: 0.8737 - val_loss: 0.3342 - val_acc: 0.9138\n",
      "Epoch 395/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 0.4564 - acc: 0.8803 - val_loss: 0.3466 - val_acc: 0.9132\n",
      "Epoch 396/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.4582 - acc: 0.8728 - val_loss: 0.3430 - val_acc: 0.9158\n",
      "Epoch 397/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.4555 - acc: 0.8745 - val_loss: 0.3470 - val_acc: 0.9138\n",
      "Epoch 398/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.4521 - acc: 0.8751 - val_loss: 0.3456 - val_acc: 0.9165\n",
      "Epoch 399/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.4475 - acc: 0.8734 - val_loss: 0.3317 - val_acc: 0.9178\n",
      "Epoch 400/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.4347 - acc: 0.8808 - val_loss: 0.3449 - val_acc: 0.9125\n",
      "Epoch 401/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.4408 - acc: 0.8811 - val_loss: 0.3302 - val_acc: 0.9198\n",
      "Epoch 402/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.4457 - acc: 0.8737 - val_loss: 0.3507 - val_acc: 0.9138\n",
      "Epoch 403/600\n",
      "3491/3491 [==============================] - 1s 256us/step - loss: 0.4461 - acc: 0.8765 - val_loss: 0.3322 - val_acc: 0.9172\n",
      "Epoch 404/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.4444 - acc: 0.8765 - val_loss: 0.3449 - val_acc: 0.9118\n",
      "Epoch 405/600\n",
      "3491/3491 [==============================] - 1s 244us/step - loss: 0.4555 - acc: 0.8717 - val_loss: 0.3519 - val_acc: 0.9125\n",
      "Epoch 406/600\n",
      "3491/3491 [==============================] - 1s 256us/step - loss: 0.4611 - acc: 0.8717 - val_loss: 0.3387 - val_acc: 0.9158\n",
      "Epoch 407/600\n",
      "3491/3491 [==============================] - 1s 252us/step - loss: 0.4484 - acc: 0.8785 - val_loss: 0.3354 - val_acc: 0.9158\n",
      "Epoch 408/600\n",
      "3491/3491 [==============================] - 1s 256us/step - loss: 0.4495 - acc: 0.8800 - val_loss: 0.3385 - val_acc: 0.9178\n",
      "Epoch 409/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.4554 - acc: 0.8748 - val_loss: 0.3457 - val_acc: 0.9152\n",
      "Epoch 410/600\n",
      "3491/3491 [==============================] - 1s 302us/step - loss: 0.4512 - acc: 0.8760 - val_loss: 0.3362 - val_acc: 0.9165\n",
      "Epoch 411/600\n",
      "3491/3491 [==============================] - 1s 301us/step - loss: 0.4391 - acc: 0.8820 - val_loss: 0.3381 - val_acc: 0.9152\n",
      "Epoch 412/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.4347 - acc: 0.8777 - val_loss: 0.3384 - val_acc: 0.9178\n",
      "Epoch 413/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.4532 - acc: 0.8765 - val_loss: 0.3392 - val_acc: 0.9185\n",
      "Epoch 414/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.4365 - acc: 0.8748 - val_loss: 0.3384 - val_acc: 0.9145\n",
      "Epoch 415/600\n",
      "3491/3491 [==============================] - 1s 291us/step - loss: 0.4369 - acc: 0.8711 - val_loss: 0.3307 - val_acc: 0.9178\n",
      "Epoch 416/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.4481 - acc: 0.8763 - val_loss: 0.3468 - val_acc: 0.9205\n",
      "Epoch 417/600\n",
      "3491/3491 [==============================] - 1s 313us/step - loss: 0.4345 - acc: 0.8803 - val_loss: 0.3378 - val_acc: 0.9172\n",
      "Epoch 418/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.4141 - acc: 0.8911 - val_loss: 0.3442 - val_acc: 0.9118\n",
      "Epoch 419/600\n",
      "3491/3491 [==============================] - 1s 313us/step - loss: 0.4389 - acc: 0.8774 - val_loss: 0.3457 - val_acc: 0.9178\n",
      "Epoch 420/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.4279 - acc: 0.8823 - val_loss: 0.3261 - val_acc: 0.9185\n",
      "Epoch 421/600\n",
      "3491/3491 [==============================] - 1s 289us/step - loss: 0.4474 - acc: 0.8765 - val_loss: 0.3443 - val_acc: 0.9145\n",
      "Epoch 422/600\n",
      "3491/3491 [==============================] - 1s 289us/step - loss: 0.4315 - acc: 0.8848 - val_loss: 0.3458 - val_acc: 0.9152\n",
      "Epoch 423/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 0.4262 - acc: 0.8805 - val_loss: 0.3345 - val_acc: 0.9158\n",
      "Epoch 424/600\n",
      "3491/3491 [==============================] - 1s 319us/step - loss: 0.4284 - acc: 0.8803 - val_loss: 0.3342 - val_acc: 0.9158\n",
      "Epoch 425/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.4336 - acc: 0.8754 - val_loss: 0.3328 - val_acc: 0.9152\n",
      "Epoch 426/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.4196 - acc: 0.8803 - val_loss: 0.3289 - val_acc: 0.9165\n",
      "Epoch 427/600\n",
      "3491/3491 [==============================] - 1s 251us/step - loss: 0.4314 - acc: 0.8794 - val_loss: 0.3193 - val_acc: 0.9178\n",
      "Epoch 428/600\n",
      "3491/3491 [==============================] - 1s 251us/step - loss: 0.4346 - acc: 0.8780 - val_loss: 0.3242 - val_acc: 0.9178\n",
      "Epoch 429/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 0.4189 - acc: 0.8860 - val_loss: 0.3202 - val_acc: 0.9205\n",
      "Epoch 430/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 0.4302 - acc: 0.8777 - val_loss: 0.3353 - val_acc: 0.9165\n",
      "Epoch 431/600\n",
      "3491/3491 [==============================] - 1s 255us/step - loss: 0.4545 - acc: 0.8748 - val_loss: 0.3450 - val_acc: 0.9145\n",
      "Epoch 432/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.4346 - acc: 0.8797 - val_loss: 0.3395 - val_acc: 0.9158\n",
      "Epoch 433/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 0.4051 - acc: 0.8846 - val_loss: 0.3359 - val_acc: 0.9192\n",
      "Epoch 434/600\n",
      "3491/3491 [==============================] - 1s 301us/step - loss: 0.4190 - acc: 0.8783 - val_loss: 0.3450 - val_acc: 0.9165\n",
      "Epoch 435/600\n",
      "3491/3491 [==============================] - 1s 260us/step - loss: 0.4221 - acc: 0.8763 - val_loss: 0.3561 - val_acc: 0.9138\n",
      "Epoch 436/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 0.4176 - acc: 0.8857 - val_loss: 0.3409 - val_acc: 0.9192\n",
      "Epoch 437/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.4296 - acc: 0.8866 - val_loss: 0.3379 - val_acc: 0.9185\n",
      "Epoch 438/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 0.4176 - acc: 0.8808 - val_loss: 0.3363 - val_acc: 0.9185\n",
      "Epoch 439/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 0.4026 - acc: 0.8828 - val_loss: 0.3326 - val_acc: 0.9185\n",
      "Epoch 440/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.4070 - acc: 0.8897 - val_loss: 0.3279 - val_acc: 0.9198\n",
      "Epoch 441/600\n",
      "3491/3491 [==============================] - 1s 263us/step - loss: 0.4286 - acc: 0.8763 - val_loss: 0.3285 - val_acc: 0.9178\n",
      "Epoch 442/600\n",
      "3491/3491 [==============================] - 1s 249us/step - loss: 0.4153 - acc: 0.8871 - val_loss: 0.3304 - val_acc: 0.9198\n",
      "Epoch 443/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.4074 - acc: 0.8869 - val_loss: 0.3312 - val_acc: 0.9172\n",
      "Epoch 444/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.4050 - acc: 0.8894 - val_loss: 0.3429 - val_acc: 0.9165\n",
      "Epoch 445/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 0.4266 - acc: 0.8828 - val_loss: 0.3375 - val_acc: 0.9145\n",
      "Epoch 446/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 0.4278 - acc: 0.8826 - val_loss: 0.3398 - val_acc: 0.9125\n",
      "Epoch 447/600\n",
      "3491/3491 [==============================] - 1s 298us/step - loss: 0.4200 - acc: 0.8823 - val_loss: 0.3410 - val_acc: 0.9178\n",
      "Epoch 448/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.3993 - acc: 0.8857 - val_loss: 0.3264 - val_acc: 0.9165\n",
      "Epoch 449/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 0.3991 - acc: 0.8840 - val_loss: 0.3294 - val_acc: 0.9205\n",
      "Epoch 450/600\n",
      "3491/3491 [==============================] - 1s 259us/step - loss: 0.4121 - acc: 0.8886 - val_loss: 0.3285 - val_acc: 0.9192\n",
      "Epoch 451/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.4084 - acc: 0.8891 - val_loss: 0.3266 - val_acc: 0.9205\n",
      "Epoch 452/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 0.4321 - acc: 0.8837 - val_loss: 0.3425 - val_acc: 0.9205\n",
      "Epoch 453/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.4023 - acc: 0.8909 - val_loss: 0.3363 - val_acc: 0.9192\n",
      "Epoch 454/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 0.4199 - acc: 0.8848 - val_loss: 0.3365 - val_acc: 0.9192\n",
      "Epoch 455/600\n",
      "3491/3491 [==============================] - 1s 329us/step - loss: 0.4133 - acc: 0.8803 - val_loss: 0.3345 - val_acc: 0.9205\n",
      "Epoch 456/600\n",
      "3491/3491 [==============================] - 1s 372us/step - loss: 0.4192 - acc: 0.8871 - val_loss: 0.3405 - val_acc: 0.9192\n",
      "Epoch 457/600\n",
      "3491/3491 [==============================] - 1s 377us/step - loss: 0.4028 - acc: 0.8903 - val_loss: 0.3379 - val_acc: 0.9185\n",
      "Epoch 458/600\n",
      "3491/3491 [==============================] - 1s 375us/step - loss: 0.4096 - acc: 0.8897 - val_loss: 0.3167 - val_acc: 0.9192\n",
      "Epoch 459/600\n",
      "3491/3491 [==============================] - 1s 343us/step - loss: 0.4115 - acc: 0.8843 - val_loss: 0.3302 - val_acc: 0.9185\n",
      "Epoch 460/600\n",
      "3491/3491 [==============================] - 1s 333us/step - loss: 0.4207 - acc: 0.8843 - val_loss: 0.3270 - val_acc: 0.9192\n",
      "Epoch 461/600\n",
      "3491/3491 [==============================] - 1s 356us/step - loss: 0.4200 - acc: 0.8886 - val_loss: 0.3308 - val_acc: 0.9165\n",
      "Epoch 462/600\n",
      "3491/3491 [==============================] - 1s 365us/step - loss: 0.3941 - acc: 0.8909 - val_loss: 0.3375 - val_acc: 0.9198\n",
      "Epoch 463/600\n",
      "3491/3491 [==============================] - 1s 355us/step - loss: 0.4241 - acc: 0.8837 - val_loss: 0.3249 - val_acc: 0.9192\n",
      "Epoch 464/600\n",
      "3491/3491 [==============================] - 1s 344us/step - loss: 0.3897 - acc: 0.8917 - val_loss: 0.3292 - val_acc: 0.9185\n",
      "Epoch 465/600\n",
      "3491/3491 [==============================] - 1s 339us/step - loss: 0.4073 - acc: 0.8848 - val_loss: 0.3284 - val_acc: 0.9205\n",
      "Epoch 466/600\n",
      "3491/3491 [==============================] - 1s 343us/step - loss: 0.4067 - acc: 0.8886 - val_loss: 0.3297 - val_acc: 0.9178\n",
      "Epoch 467/600\n",
      "3491/3491 [==============================] - 1s 331us/step - loss: 0.4070 - acc: 0.8863 - val_loss: 0.3252 - val_acc: 0.9232\n",
      "Epoch 468/600\n",
      "3491/3491 [==============================] - 1s 353us/step - loss: 0.3982 - acc: 0.8923 - val_loss: 0.3291 - val_acc: 0.9192\n",
      "Epoch 469/600\n",
      "3491/3491 [==============================] - 1s 341us/step - loss: 0.4057 - acc: 0.8820 - val_loss: 0.3231 - val_acc: 0.9178\n",
      "Epoch 470/600\n",
      "3491/3491 [==============================] - 1s 359us/step - loss: 0.3889 - acc: 0.8923 - val_loss: 0.3291 - val_acc: 0.9198\n",
      "Epoch 471/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 1s 319us/step - loss: 0.4240 - acc: 0.8828 - val_loss: 0.3234 - val_acc: 0.9192\n",
      "Epoch 472/600\n",
      "3491/3491 [==============================] - 1s 355us/step - loss: 0.3917 - acc: 0.8940 - val_loss: 0.3223 - val_acc: 0.9225\n",
      "Epoch 473/600\n",
      "3491/3491 [==============================] - 1s 357us/step - loss: 0.3973 - acc: 0.8946 - val_loss: 0.3273 - val_acc: 0.9185\n",
      "Epoch 474/600\n",
      "3491/3491 [==============================] - 1s 344us/step - loss: 0.3964 - acc: 0.8869 - val_loss: 0.3342 - val_acc: 0.9165\n",
      "Epoch 475/600\n",
      "3491/3491 [==============================] - 1s 365us/step - loss: 0.3982 - acc: 0.8863 - val_loss: 0.3293 - val_acc: 0.9238\n",
      "Epoch 476/600\n",
      "3491/3491 [==============================] - 1s 356us/step - loss: 0.3932 - acc: 0.8906 - val_loss: 0.3272 - val_acc: 0.9212\n",
      "Epoch 477/600\n",
      "3491/3491 [==============================] - 1s 372us/step - loss: 0.4125 - acc: 0.8834 - val_loss: 0.3352 - val_acc: 0.9232\n",
      "Epoch 478/600\n",
      "3491/3491 [==============================] - 1s 353us/step - loss: 0.3934 - acc: 0.8831 - val_loss: 0.3219 - val_acc: 0.9178\n",
      "Epoch 479/600\n",
      "3491/3491 [==============================] - 1s 366us/step - loss: 0.3873 - acc: 0.8906 - val_loss: 0.3298 - val_acc: 0.9185\n",
      "Epoch 480/600\n",
      "3491/3491 [==============================] - 1s 372us/step - loss: 0.4203 - acc: 0.8843 - val_loss: 0.3061 - val_acc: 0.9172\n",
      "Epoch 481/600\n",
      "3491/3491 [==============================] - 1s 355us/step - loss: 0.3961 - acc: 0.8932 - val_loss: 0.3182 - val_acc: 0.9192\n",
      "Epoch 482/600\n",
      "3491/3491 [==============================] - 1s 356us/step - loss: 0.3996 - acc: 0.8894 - val_loss: 0.3188 - val_acc: 0.9185\n",
      "Epoch 483/600\n",
      "3491/3491 [==============================] - 1s 365us/step - loss: 0.3895 - acc: 0.8923 - val_loss: 0.3265 - val_acc: 0.9198\n",
      "Epoch 484/600\n",
      "3491/3491 [==============================] - 1s 358us/step - loss: 0.3962 - acc: 0.8894 - val_loss: 0.3205 - val_acc: 0.9192\n",
      "Epoch 485/600\n",
      "3491/3491 [==============================] - 1s 317us/step - loss: 0.3861 - acc: 0.8923 - val_loss: 0.3155 - val_acc: 0.9212\n",
      "Epoch 486/600\n",
      "3491/3491 [==============================] - 1s 326us/step - loss: 0.3893 - acc: 0.8937 - val_loss: 0.3227 - val_acc: 0.9212\n",
      "Epoch 487/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 0.3972 - acc: 0.8906 - val_loss: 0.3226 - val_acc: 0.9192\n",
      "Epoch 488/600\n",
      "3491/3491 [==============================] - 1s 307us/step - loss: 0.3722 - acc: 0.8963 - val_loss: 0.3191 - val_acc: 0.9185\n",
      "Epoch 489/600\n",
      "3491/3491 [==============================] - 1s 309us/step - loss: 0.3809 - acc: 0.8940 - val_loss: 0.3102 - val_acc: 0.9212\n",
      "Epoch 490/600\n",
      "3491/3491 [==============================] - 1s 356us/step - loss: 0.3898 - acc: 0.8891 - val_loss: 0.3180 - val_acc: 0.9178\n",
      "Epoch 491/600\n",
      "3491/3491 [==============================] - 1s 340us/step - loss: 0.3836 - acc: 0.8909 - val_loss: 0.3167 - val_acc: 0.9218\n",
      "Epoch 492/600\n",
      "3491/3491 [==============================] - 1s 322us/step - loss: 0.3974 - acc: 0.8891 - val_loss: 0.3185 - val_acc: 0.9218\n",
      "Epoch 493/600\n",
      "3491/3491 [==============================] - 1s 315us/step - loss: 0.3731 - acc: 0.8926 - val_loss: 0.3273 - val_acc: 0.9205\n",
      "Epoch 494/600\n",
      "3491/3491 [==============================] - 1s 338us/step - loss: 0.4078 - acc: 0.8823 - val_loss: 0.3123 - val_acc: 0.9185\n",
      "Epoch 495/600\n",
      "3491/3491 [==============================] - 1s 311us/step - loss: 0.3691 - acc: 0.8989 - val_loss: 0.3158 - val_acc: 0.9212\n",
      "Epoch 496/600\n",
      "3491/3491 [==============================] - 1s 313us/step - loss: 0.3956 - acc: 0.8874 - val_loss: 0.3165 - val_acc: 0.9198\n",
      "Epoch 497/600\n",
      "3491/3491 [==============================] - 1s 310us/step - loss: 0.3958 - acc: 0.8897 - val_loss: 0.3023 - val_acc: 0.9225\n",
      "Epoch 498/600\n",
      "3491/3491 [==============================] - 1s 326us/step - loss: 0.3905 - acc: 0.8880 - val_loss: 0.3190 - val_acc: 0.9205\n",
      "Epoch 499/600\n",
      "3491/3491 [==============================] - 1s 337us/step - loss: 0.3894 - acc: 0.8874 - val_loss: 0.3088 - val_acc: 0.9205\n",
      "Epoch 500/600\n",
      "3491/3491 [==============================] - 1s 323us/step - loss: 0.3887 - acc: 0.8997 - val_loss: 0.3111 - val_acc: 0.9225\n",
      "Epoch 501/600\n",
      "3491/3491 [==============================] - 1s 302us/step - loss: 0.3846 - acc: 0.8926 - val_loss: 0.3074 - val_acc: 0.9212\n",
      "Epoch 502/600\n",
      "3491/3491 [==============================] - 1s 323us/step - loss: 0.3901 - acc: 0.8877 - val_loss: 0.3176 - val_acc: 0.9218\n",
      "Epoch 503/600\n",
      "3491/3491 [==============================] - 1s 332us/step - loss: 0.3642 - acc: 0.8960 - val_loss: 0.3254 - val_acc: 0.9225\n",
      "Epoch 504/600\n",
      "3491/3491 [==============================] - 1s 319us/step - loss: 0.4025 - acc: 0.8934 - val_loss: 0.3123 - val_acc: 0.9218\n",
      "Epoch 505/600\n",
      "3491/3491 [==============================] - 1s 323us/step - loss: 0.3746 - acc: 0.8960 - val_loss: 0.3180 - val_acc: 0.9218\n",
      "Epoch 506/600\n",
      "3491/3491 [==============================] - 1s 325us/step - loss: 0.3736 - acc: 0.8900 - val_loss: 0.3275 - val_acc: 0.9185\n",
      "Epoch 507/600\n",
      "3491/3491 [==============================] - 1s 333us/step - loss: 0.3934 - acc: 0.8897 - val_loss: 0.3155 - val_acc: 0.9225\n",
      "Epoch 508/600\n",
      "3491/3491 [==============================] - 1s 314us/step - loss: 0.3872 - acc: 0.8932 - val_loss: 0.3095 - val_acc: 0.9232\n",
      "Epoch 509/600\n",
      "3491/3491 [==============================] - 1s 311us/step - loss: 0.3619 - acc: 0.8914 - val_loss: 0.3076 - val_acc: 0.9245\n",
      "Epoch 510/600\n",
      "3491/3491 [==============================] - 1s 348us/step - loss: 0.3846 - acc: 0.8897 - val_loss: 0.3083 - val_acc: 0.9252\n",
      "Epoch 511/600\n",
      "3491/3491 [==============================] - 1s 294us/step - loss: 0.3799 - acc: 0.8894 - val_loss: 0.3125 - val_acc: 0.9238\n",
      "Epoch 512/600\n",
      "3491/3491 [==============================] - 1s 301us/step - loss: 0.3631 - acc: 0.8995 - val_loss: 0.3140 - val_acc: 0.9252\n",
      "Epoch 513/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.3823 - acc: 0.8871 - val_loss: 0.3154 - val_acc: 0.9225\n",
      "Epoch 514/600\n",
      "3491/3491 [==============================] - 1s 300us/step - loss: 0.3959 - acc: 0.8954 - val_loss: 0.3142 - val_acc: 0.9245\n",
      "Epoch 515/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.3887 - acc: 0.8900 - val_loss: 0.3101 - val_acc: 0.9245\n",
      "Epoch 516/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 0.3870 - acc: 0.8911 - val_loss: 0.3195 - val_acc: 0.9225\n",
      "Epoch 517/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 0.3856 - acc: 0.8954 - val_loss: 0.3091 - val_acc: 0.9232\n",
      "Epoch 518/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.3666 - acc: 0.9035 - val_loss: 0.3056 - val_acc: 0.9225\n",
      "Epoch 519/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.3640 - acc: 0.8954 - val_loss: 0.3176 - val_acc: 0.9218\n",
      "Epoch 520/600\n",
      "3491/3491 [==============================] - 1s 296us/step - loss: 0.3709 - acc: 0.8997 - val_loss: 0.2937 - val_acc: 0.9252\n",
      "Epoch 521/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.3578 - acc: 0.8995 - val_loss: 0.2970 - val_acc: 0.9238\n",
      "Epoch 522/600\n",
      "3491/3491 [==============================] - 1s 335us/step - loss: 0.3835 - acc: 0.8920 - val_loss: 0.2990 - val_acc: 0.9218\n",
      "Epoch 523/600\n",
      "3491/3491 [==============================] - 1s 334us/step - loss: 0.3811 - acc: 0.8894 - val_loss: 0.3098 - val_acc: 0.9245\n",
      "Epoch 524/600\n",
      "3491/3491 [==============================] - 1s 331us/step - loss: 0.3655 - acc: 0.8914 - val_loss: 0.3161 - val_acc: 0.9238\n",
      "Epoch 525/600\n",
      "3491/3491 [==============================] - 1s 329us/step - loss: 0.3880 - acc: 0.8891 - val_loss: 0.3203 - val_acc: 0.9245\n",
      "Epoch 526/600\n",
      "3491/3491 [==============================] - 1s 325us/step - loss: 0.3623 - acc: 0.8952 - val_loss: 0.3152 - val_acc: 0.9218\n",
      "Epoch 527/600\n",
      "3491/3491 [==============================] - 1s 309us/step - loss: 0.3588 - acc: 0.9017 - val_loss: 0.3024 - val_acc: 0.9245\n",
      "Epoch 528/600\n",
      "3491/3491 [==============================] - 1s 319us/step - loss: 0.3621 - acc: 0.8977 - val_loss: 0.3109 - val_acc: 0.9245\n",
      "Epoch 529/600\n",
      "3491/3491 [==============================] - 1s 383us/step - loss: 0.3744 - acc: 0.8949 - val_loss: 0.3094 - val_acc: 0.9218\n",
      "Epoch 530/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 1s 335us/step - loss: 0.3796 - acc: 0.8886 - val_loss: 0.3003 - val_acc: 0.9232\n",
      "Epoch 531/600\n",
      "3491/3491 [==============================] - 1s 288us/step - loss: 0.3602 - acc: 0.8972 - val_loss: 0.3118 - val_acc: 0.9232\n",
      "Epoch 532/600\n",
      "3491/3491 [==============================] - 1s 275us/step - loss: 0.3610 - acc: 0.8980 - val_loss: 0.3121 - val_acc: 0.9232\n",
      "Epoch 533/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 0.3809 - acc: 0.8914 - val_loss: 0.3222 - val_acc: 0.9212\n",
      "Epoch 534/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.3859 - acc: 0.8969 - val_loss: 0.3155 - val_acc: 0.9225\n",
      "Epoch 535/600\n",
      "3491/3491 [==============================] - 1s 294us/step - loss: 0.3956 - acc: 0.8869 - val_loss: 0.3062 - val_acc: 0.9225\n",
      "Epoch 536/600\n",
      "3491/3491 [==============================] - 1s 348us/step - loss: 0.3703 - acc: 0.8906 - val_loss: 0.3068 - val_acc: 0.9232\n",
      "Epoch 537/600\n",
      "3491/3491 [==============================] - 1s 322us/step - loss: 0.3746 - acc: 0.8949 - val_loss: 0.3012 - val_acc: 0.9252\n",
      "Epoch 538/600\n",
      "3491/3491 [==============================] - 1s 320us/step - loss: 0.3480 - acc: 0.9032 - val_loss: 0.2942 - val_acc: 0.9252\n",
      "Epoch 539/600\n",
      "3491/3491 [==============================] - 1s 296us/step - loss: 0.3496 - acc: 0.9035 - val_loss: 0.3000 - val_acc: 0.9245\n",
      "Epoch 540/600\n",
      "3491/3491 [==============================] - 1s 361us/step - loss: 0.3604 - acc: 0.8940 - val_loss: 0.2983 - val_acc: 0.9238\n",
      "Epoch 541/600\n",
      "3491/3491 [==============================] - 1s 378us/step - loss: 0.3513 - acc: 0.8963 - val_loss: 0.3168 - val_acc: 0.9225\n",
      "Epoch 542/600\n",
      "3491/3491 [==============================] - 1s 428us/step - loss: 0.3858 - acc: 0.8957 - val_loss: 0.2940 - val_acc: 0.9272\n",
      "Epoch 543/600\n",
      "3491/3491 [==============================] - 1s 362us/step - loss: 0.3543 - acc: 0.9023 - val_loss: 0.3001 - val_acc: 0.9252\n",
      "Epoch 544/600\n",
      "3491/3491 [==============================] - ETA: 0s - loss: 0.3665 - acc: 0.893 - 1s 283us/step - loss: 0.3686 - acc: 0.8937 - val_loss: 0.3077 - val_acc: 0.9252\n",
      "Epoch 545/600\n",
      "3491/3491 [==============================] - 1s 273us/step - loss: 0.3390 - acc: 0.9040 - val_loss: 0.3134 - val_acc: 0.9265\n",
      "Epoch 546/600\n",
      "3491/3491 [==============================] - 1s 290us/step - loss: 0.3529 - acc: 0.9026 - val_loss: 0.3046 - val_acc: 0.9252\n",
      "Epoch 547/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.3669 - acc: 0.8992 - val_loss: 0.2976 - val_acc: 0.9245\n",
      "Epoch 548/600\n",
      "3491/3491 [==============================] - 1s 277us/step - loss: 0.3548 - acc: 0.9009 - val_loss: 0.3008 - val_acc: 0.9272\n",
      "Epoch 549/600\n",
      "3491/3491 [==============================] - 1s 297us/step - loss: 0.3703 - acc: 0.8923 - val_loss: 0.2988 - val_acc: 0.9272\n",
      "Epoch 550/600\n",
      "3491/3491 [==============================] - 1s 278us/step - loss: 0.3657 - acc: 0.8995 - val_loss: 0.3073 - val_acc: 0.9245\n",
      "Epoch 551/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 0.3670 - acc: 0.8983 - val_loss: 0.3075 - val_acc: 0.9259\n",
      "Epoch 552/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.3597 - acc: 0.8992 - val_loss: 0.3012 - val_acc: 0.9279\n",
      "Epoch 553/600\n",
      "3491/3491 [==============================] - 1s 285us/step - loss: 0.3395 - acc: 0.9003 - val_loss: 0.3012 - val_acc: 0.9245\n",
      "Epoch 554/600\n",
      "3491/3491 [==============================] - 1s 301us/step - loss: 0.3498 - acc: 0.9006 - val_loss: 0.3011 - val_acc: 0.9225\n",
      "Epoch 555/600\n",
      "3491/3491 [==============================] - 1s 274us/step - loss: 0.3459 - acc: 0.8995 - val_loss: 0.2996 - val_acc: 0.9238\n",
      "Epoch 556/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.3676 - acc: 0.8911 - val_loss: 0.2991 - val_acc: 0.9238\n",
      "Epoch 557/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.3465 - acc: 0.9038 - val_loss: 0.2861 - val_acc: 0.9285\n",
      "Epoch 558/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.3315 - acc: 0.9035 - val_loss: 0.2810 - val_acc: 0.9272\n",
      "Epoch 559/600\n",
      "3491/3491 [==============================] - 1s 281us/step - loss: 0.3567 - acc: 0.8977 - val_loss: 0.2869 - val_acc: 0.9252\n",
      "Epoch 560/600\n",
      "3491/3491 [==============================] - 1s 295us/step - loss: 0.3734 - acc: 0.8966 - val_loss: 0.2876 - val_acc: 0.9245\n",
      "Epoch 561/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 0.3641 - acc: 0.8966 - val_loss: 0.2921 - val_acc: 0.9272\n",
      "Epoch 562/600\n",
      "3491/3491 [==============================] - 1s 266us/step - loss: 0.3587 - acc: 0.9029 - val_loss: 0.2985 - val_acc: 0.9272\n",
      "Epoch 563/600\n",
      "3491/3491 [==============================] - 1s 248us/step - loss: 0.3580 - acc: 0.8937 - val_loss: 0.2971 - val_acc: 0.9245\n",
      "Epoch 564/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.3593 - acc: 0.8980 - val_loss: 0.2965 - val_acc: 0.9265\n",
      "Epoch 565/600\n",
      "3491/3491 [==============================] - 1s 265us/step - loss: 0.3509 - acc: 0.9063 - val_loss: 0.3040 - val_acc: 0.9245\n",
      "Epoch 566/600\n",
      "3491/3491 [==============================] - 1s 253us/step - loss: 0.3437 - acc: 0.9006 - val_loss: 0.2985 - val_acc: 0.9238\n",
      "Epoch 567/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 0.3647 - acc: 0.8989 - val_loss: 0.2955 - val_acc: 0.9265\n",
      "Epoch 568/600\n",
      "3491/3491 [==============================] - 1s 251us/step - loss: 0.3416 - acc: 0.9038 - val_loss: 0.2940 - val_acc: 0.9259\n",
      "Epoch 569/600\n",
      "3491/3491 [==============================] - 1s 276us/step - loss: 0.3479 - acc: 0.9032 - val_loss: 0.2965 - val_acc: 0.9252\n",
      "Epoch 570/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.3637 - acc: 0.8937 - val_loss: 0.2950 - val_acc: 0.9259\n",
      "Epoch 571/600\n",
      "3491/3491 [==============================] - 1s 398us/step - loss: 0.3635 - acc: 0.8975 - val_loss: 0.2948 - val_acc: 0.9279\n",
      "Epoch 572/600\n",
      "3491/3491 [==============================] - 1s 351us/step - loss: 0.3377 - acc: 0.9026 - val_loss: 0.2953 - val_acc: 0.9265\n",
      "Epoch 573/600\n",
      "3491/3491 [==============================] - 1s 308us/step - loss: 0.3540 - acc: 0.9017 - val_loss: 0.2964 - val_acc: 0.9272\n",
      "Epoch 574/600\n",
      "3491/3491 [==============================] - 1s 305us/step - loss: 0.3437 - acc: 0.8992 - val_loss: 0.2971 - val_acc: 0.9252\n",
      "Epoch 575/600\n",
      "3491/3491 [==============================] - 1s 306us/step - loss: 0.3553 - acc: 0.8989 - val_loss: 0.2982 - val_acc: 0.9259\n",
      "Epoch 576/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.3431 - acc: 0.8937 - val_loss: 0.2964 - val_acc: 0.9265\n",
      "Epoch 577/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 0.3457 - acc: 0.8983 - val_loss: 0.2930 - val_acc: 0.9279\n",
      "Epoch 578/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 0.3157 - acc: 0.9129 - val_loss: 0.2944 - val_acc: 0.9279\n",
      "Epoch 579/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.3636 - acc: 0.8960 - val_loss: 0.2968 - val_acc: 0.9285\n",
      "Epoch 580/600\n",
      "3491/3491 [==============================] - 1s 269us/step - loss: 0.3511 - acc: 0.8966 - val_loss: 0.2978 - val_acc: 0.9279\n",
      "Epoch 581/600\n",
      "3491/3491 [==============================] - 1s 287us/step - loss: 0.3361 - acc: 0.9058 - val_loss: 0.2932 - val_acc: 0.9265\n",
      "Epoch 582/600\n",
      "3491/3491 [==============================] - 1s 292us/step - loss: 0.3420 - acc: 0.9017 - val_loss: 0.2913 - val_acc: 0.9265\n",
      "Epoch 583/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.3523 - acc: 0.9003 - val_loss: 0.2947 - val_acc: 0.9292\n",
      "Epoch 584/600\n",
      "3491/3491 [==============================] - 1s 261us/step - loss: 0.3402 - acc: 0.9003 - val_loss: 0.2934 - val_acc: 0.9292\n",
      "Epoch 585/600\n",
      "3491/3491 [==============================] - 1s 257us/step - loss: 0.3556 - acc: 0.8972 - val_loss: 0.2950 - val_acc: 0.9285\n",
      "Epoch 586/600\n",
      "3491/3491 [==============================] - 1s 254us/step - loss: 0.3576 - acc: 0.8992 - val_loss: 0.2923 - val_acc: 0.9259\n",
      "Epoch 587/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.3644 - acc: 0.8906 - val_loss: 0.2950 - val_acc: 0.9238\n",
      "Epoch 588/600\n",
      "3491/3491 [==============================] - 1s 280us/step - loss: 0.3667 - acc: 0.8943 - val_loss: 0.2924 - val_acc: 0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/600\n",
      "3491/3491 [==============================] - 1s 271us/step - loss: 0.3563 - acc: 0.9069 - val_loss: 0.2931 - val_acc: 0.9252\n",
      "Epoch 590/600\n",
      "3491/3491 [==============================] - 1s 268us/step - loss: 0.3414 - acc: 0.9052 - val_loss: 0.2961 - val_acc: 0.9259\n",
      "Epoch 591/600\n",
      "3491/3491 [==============================] - 1s 279us/step - loss: 0.3414 - acc: 0.9075 - val_loss: 0.2991 - val_acc: 0.9265\n",
      "Epoch 592/600\n",
      "3491/3491 [==============================] - 1s 296us/step - loss: 0.3260 - acc: 0.9055 - val_loss: 0.3040 - val_acc: 0.9292\n",
      "Epoch 593/600\n",
      "3491/3491 [==============================] - 1s 264us/step - loss: 0.3267 - acc: 0.9046 - val_loss: 0.2952 - val_acc: 0.9292\n",
      "Epoch 594/600\n",
      "3491/3491 [==============================] - 1s 293us/step - loss: 0.3514 - acc: 0.8989 - val_loss: 0.2957 - val_acc: 0.9292\n",
      "Epoch 595/600\n",
      "3491/3491 [==============================] - 1s 282us/step - loss: 0.3687 - acc: 0.9026 - val_loss: 0.2971 - val_acc: 0.9279\n",
      "Epoch 596/600\n",
      "3491/3491 [==============================] - 1s 270us/step - loss: 0.3232 - acc: 0.9138 - val_loss: 0.2947 - val_acc: 0.9272\n",
      "Epoch 597/600\n",
      "3491/3491 [==============================] - 1s 267us/step - loss: 0.3309 - acc: 0.9078 - val_loss: 0.2926 - val_acc: 0.9285\n",
      "Epoch 598/600\n",
      "3491/3491 [==============================] - 1s 286us/step - loss: 0.3571 - acc: 0.8992 - val_loss: 0.2913 - val_acc: 0.9319\n",
      "Epoch 599/600\n",
      "3491/3491 [==============================] - 1s 272us/step - loss: 0.3260 - acc: 0.9083 - val_loss: 0.2948 - val_acc: 0.9312\n",
      "Epoch 600/600\n",
      "3491/3491 [==============================] - 1s 262us/step - loss: 0.3347 - acc: 0.9058 - val_loss: 0.2965 - val_acc: 0.9299\n",
      "Successfully completed.\n"
     ]
    }
   ],
   "source": [
    "# Generate LPCC features and save them on the disk.\n",
    "print(\"Running preprocess..\")\n",
    "run_preprocess_lpcc(data_dir, str(audio_len), str(window_size), n_lpcc)\n",
    "\n",
    "# Load saved LPCC coefficients from npy files\n",
    "print(\"Loading LPCC data..\")\n",
    "X, y = load_features_lpcc(data_dir, str(audio_len), str(window_size), n_lpcc)\n",
    "\n",
    "# Reshape and one hot encode the data\n",
    "X = X.reshape(X.shape[0], 10, -1, 1)\n",
    "y_norm = one_hot_encode(y)\n",
    "\n",
    "# Split the samples and training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_norm, test_size=0.3, random_state=64)\n",
    "\n",
    "# Build the CNN\n",
    "print(\"Building the model..\")\n",
    "model = build_model_lpcc(lpcc_shape, n_lpcc + 1, n_samples)\n",
    "\n",
    "# Train the model.\n",
    "train_result = model.fit(np.array(X_train), y_train,\n",
    "      batch_size=16,\n",
    "      epochs=600,\n",
    "      verbose=1,\n",
    "      shuffle = True,\n",
    "     validation_data=(np.array(X_test), y_test))\n",
    "\n",
    "# Save the trained model weights\n",
    "model.save_weights(os.path.join('..', 'neural-net-weights', \\\n",
    "                                'lpcc_model_weights_' + str(n_lpcc) + '_' + \\\n",
    "                                    str(audio_len) + '_' + str(window_size) + '.h5'))\n",
    "\n",
    "print(\"Successfully completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
