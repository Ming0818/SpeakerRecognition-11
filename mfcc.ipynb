{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-050b52373b23>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-050b52373b23>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Steps to Perform for MFCC Transfer Learning\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Steps to Perform for MFCC Transfer Learning\n",
    "Step 1: Load the files and convert to mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() got an unexpected keyword argument 'W_regularizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4dfa204bfa32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m model.compile(loss=hinge,\n\u001b[0;32m     91\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: add() got an unexpected keyword argument 'W_regularizer'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa as lp\n",
    "import subprocess\n",
    "import os\n",
    "from IPython.core.debugger import set_trace\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# This function is to convert mp3 to wav currently in disuse\n",
    "def convert_audio_to_wav(filename):\n",
    "    subprocess.call(['ffmpeg', '-i', filename,\n",
    "                   str(filename.split(\".mp3\")[0])+\".wav\"])\n",
    "    \n",
    "#Function to convert mp3 audio to mfcc shapes    \n",
    "def convert_to_mfcc(filename, max_length):\n",
    "   # convert_audio_to_wav(filename)\n",
    "    wave, sr = lp.load(filename, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc = lp.feature.mfcc(wave, sr=16000)\n",
    "     # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_length > mfcc.shape[1]):\n",
    "        pad_width = max_length - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_length]\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def create_training_data(pathname_training):\n",
    "    #set_trace()\n",
    "    mfcc_array=[]\n",
    "    subdirs=[x[1] for x in os.walk(pathname_training)][0]\n",
    "    for subdir in subdirs:\n",
    "        subdir_path=pathname_training+\"\\\\\" + subdir\n",
    "        files2=[x[2] for x in os.walk(subdir_path)][0]\n",
    "        print(files2)\n",
    "        for file_name in files2:\n",
    "            file_path=subdir_path+\"\\\\\"+file_name\n",
    "            mfcc_of_file=convert_to_mfcc(file_path,11)\n",
    "            mfcc_array.append(mfcc_of_file)\n",
    "        np.save(subdir,mfcc_array)\n",
    "        mfcc_array=[]\n",
    "\n",
    "#create_training_data(\"C:\\Users\\Ashok\\Documents\\GitHub\\SpeakerRecognition\\Training\")  \n",
    "\n",
    "def get_mfcc_from_file(location_of_mfcc):\n",
    "    mfcc_files=os.listdir(location_of_mfcc)\n",
    "    return mfcc_files\n",
    "\n",
    "#get_mfcc_from_file( os.getcwd()+\"\\\\mfcc_files\")\n",
    "\n",
    "def get_train_test(ratio_of_split, random_state=42):\n",
    "    # Get available labels\n",
    "    mfcc_labels= get_mfcc_from_file( os.getcwd()+\"\\\\mfcc_files\")\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(os.getcwd()+\"\\\\mfcc_files\\\\\"+mfcc_labels[0])\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(mfcc_labels[1:]):\n",
    "        x = np.load(os.getcwd()+\"\\\\mfcc_files\\\\\"+label)\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - ratio_of_split), random_state=random_state, shuffle=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(0.6)\n",
    "X_train = X_train.reshape(X_train.shape[0], 20, 11, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 11, 1)\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(20, 11, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_hot, batch_size=100, epochs=200, verbose=1, validation_data=(X_test, y_test_hot))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
