{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Perform for MFCC Transfer Learning\n",
    "Step 1: Load the files and convert to mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def run_preprocess(root, length, split):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            print(directory)\n",
    "            mfcc_data = []\n",
    "            npy_file = directory + '_' + 'mfcc' + '_' + '64' + '_' + length + '_' + split + '.npy'\n",
    "            if os.path.isfile(os.path.join(subdir, directory, npy_file)):\n",
    "                continue\n",
    "\n",
    "            if not os.path.isdir(os.path.join(subdir, directory, \"split\", split)):\n",
    "                subprocess.call([\"./preprocess\", os.path.join(subdir, directory), length, split])\n",
    "\n",
    "            file_path = os.path.join(subdir, directory, \"split\", split, \"wav\")\n",
    "            for filename in os.listdir(file_path):\n",
    "                y, sr = lp.load(os.path.join(file_path, filename))\n",
    "                mfcc = lp.feature.mfcc(y = y, sr = 16000, n_mfcc = 64)\n",
    "#                 print(mfcc.shape)\n",
    "                mfcc = np.pad(mfcc, pad_width=((0, 0), (0, 128)), mode='constant')\n",
    "                if mfcc.shape != (64, 128):\n",
    "                    mfcc = mfcc[:, :128]\n",
    "#                 print(mfcc.shape)\n",
    "                mfcc_data.append(mfcc)\n",
    "\n",
    "            np.save(os.path.join(subdir, directory, npy_file), np.asarray(mfcc_data))\n",
    "            print(np.asarray(mfcc_data).shape)\n",
    "            shutil.rmtree(os.path.join(subdir, directory, \"split\"), ignore_errors = True)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def rename_npy(root, length, split):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            npy_file = directory + '_' + length + '_' + split + '.npy'\n",
    "            new_npy_file = directory + '_' + 'mfcc' + '_' + '15' + '_' + length + '_' + split + '.npy'\n",
    "            if os.path.isfile(os.path.join(subdir, directory, npy_file)):\n",
    "                shutil.move(os.path.join(subdir, directory, npy_file), os.path.join(subdir, directory, new_npy_file))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(root, length, split):\n",
    "    mfcc_data = np.zeros((0, 64, 128))\n",
    "    mfcc_label = []\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            npy_file = directory + '_' + 'mfcc' + '_' + '64' + '_' + length + '_' + split + '.npy'\n",
    "            mfcc = np.load(os.path.join(subdir, directory, npy_file))\n",
    "            mfcc_data = np.concatenate((mfcc_data, mfcc))\n",
    "            mfcc_label += mfcc.shape[0] * [directory]\n",
    "        break\n",
    "    return mfcc_data, mfcc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_split(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            shutil.rmtree(os.path.join(subdir, directory, \"split\"), ignore_errors = True)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young_folks_history_american_revolution_1503_librivox_64kb_mp3\n",
      "youngwomansguide_1501_librivox_64kb_mp3\n",
      "a_country_doctor_1504_librivox_64kb_mp3\n",
      "a_dreamers_tales_dm_1501_librivox_64kb_mp3\n",
      "adventuresbobwhite_1505_librivox_64kb_mp3\n",
      "aequanimitas_1412_librivox_64kb_mp3\n",
      "agnesgreyversion3_1501_librivox_64kb_mp3\n",
      "airplaneflyinghandbookvol3_1409_librivox_64kb_mp3\n",
      "alondonlife_1412_librivox_64kb_mp3\n",
      "ancient_modern_celebrated_freethinkers_1503_librivox_64kb_mp3\n",
      "aprendizdeconspirador_1412_librivox_64kb_mp3\n",
      "aristotles_masterpiece_1506_librivox_64kb_mp3\n",
      "artofdivinecontentment_1512_librivox_64kb_mp3\n",
      "battle-pieces_aspects_war_1501_librivox_64kb_mp3\n",
      "blackriders_1410_librivox_64kb_mp3\n",
      "boatsoftheglencarrig_1411_librivox_64kb_mp3\n",
      "bookofgoodcounsels_1506_librivox_64kb_mp3\n",
      "briefe_paulus_auswahl_1506_librivox_64kb_mp3\n",
      "britishsubject_president_1505_librivox_64kb_mp3\n",
      "canti_leopardi_1512_librivox_64kb_mp3\n",
      "lifeofcarltonparker_1409_librivox_64kb_mp3\n",
      "littlebrothertothebear_1602_librivox_64kb_mp3\n",
      "childs_garden_of_verses_1503_librivox_64kb_mp3\n",
      "company_b_307th_infantry_wc_1412_librivox_64kb_mp3\n",
      "contes_humoristiques_1505_librivox_64kb_mp3\n",
      "curlyandfloppytwistytail_1509_librivox_64kb_mp3\n",
      "deepwoodstocivilization_1502_librivox_64kb_mp3\n",
      "de_reis_naar_de_maan_1511_librivox_64kb_mp3\n",
      "dernier_des_mohicans_1604_librivox_64kb_mp3\n",
      "de_vorst_1504_librivox_64kb_mp3\n",
      "door_unreal_1508_librivox_64kb_mp3\n",
      "dubrovsky_1411_librivox_64kb_mp3\n",
      "englishgirls_first_impressions_burmah_1412_librivox_64kb_mp3\n",
      "esau_jaco_1509_librivox_64kb_mp3\n",
      "essayoncriticism_1505_librivox_64kb_mp3\n",
      "experiences_executioner_1508_librivox_64kb_mp3\n",
      "explorersandtravellers_1509_librivox_64kb_mp3\n",
      "food_gods_1603_librivox_64kb_mp3\n",
      "formation_distribution_wealth_1503_librivox_64kb_mp3\n",
      "franceatwar_1507_librivox_64kb_mp3\n",
      "greybeardsatplay_1601_librivox_64kb_mp3\n",
      "gullivers_rejser_1503_librivox_64kb_mp3\n",
      "hindu_yogi_science_breath_mj_1509_librivox_64kb_mp3\n",
      "his_last_bow_version_3_1603_librivox_64kb_mp3\n",
      "historietas_nacionales_1602_librivox_64kb_mp3\n",
      "historymathematics_1601_librivox_64kb_mp3\n",
      "how_to_write_a_novel_1502_librivox_64kb_mp3\n",
      "human_toll_1501_librivox_64kb_mp3\n",
      "jessejames_myfather_1505_librivox_64kb_mp3\n",
      "john_gutenberg_cs_1509_librivox_64kb_mp3\n",
      "journal_julius_rodman_mp_1505_librivox_64kb_mp3\n",
      "konekgorbunok_1603_librivox_64kb_mp3\n",
      "lark_1507_librivox_64kb_mp3\n",
      "lebenssucher_1601_librivox_64kb_mp3\n",
      "letters_of_pliny_1510_librivox_64kb_mp3\n",
      "littlefoldedhands_1412_librivox_64kb_mp3\n",
      "little_megs_children_1501_librivox_64kb_mp3\n",
      "littleprincess_1502_librivox_64kb_mp3\n",
      "lob_der_narrheit_1503_librivox_64kb_mp3\n",
      "marcia_schuyler_1603_librivox_64kb_mp3\n",
      "marybartonversion2_1603_librivox_64kb_mp3\n",
      "mayorofcasterbridge3_1506_librivox_64kb_mp3\n",
      "meguriai_1409_librivox_64kb_mp3\n",
      "meister_eckharts_sermons_1412_librivox_64kb_mp3\n",
      "modern_scottish_minstrel_1602_librivox_64kb_mp3\n",
      "morallettersvol1_1501_librivox_64kb_mp3\n",
      "moral_tales_1602_librivox_64kb_mp3\n",
      "mounties_in_the_news_1509_librivox_64kb_mp3\n",
      "myreminiscences_1410_librivox_64kb_mp3\n",
      "mystical_city_god_1_amb_1602_librivox_64kb_mp3\n",
      "myths_legends_great_plains_1511_librivox_64kb_mp3\n",
      "nedfranks_1504_librivox_64kb_mp3\n",
      "new_testament_kneeland_1412_librivox_64kb_mp3\n",
      "onanirishjauntingcar_1505_librivox_64kb_mp3\n",
      "parablesofthecross_1511_librivox_64kb_mp3\n",
      "pennycomequicks_1511_librivox_64kb_mp3\n",
      "philosophical_rudiments_government_society_librivox_64kb_mp3\n",
      "plateroyyo_1505_librivox_64kb_mp3\n",
      "psychologyofpeople_1604_librivox_64kb_mp3\n",
      "religiousaffections_1501_librivox_64kb_mp3\n",
      "republicofthefuture_1602_librivox_64kb_mp3\n",
      "reynardthefox_1409_librivox_64kb_mp3\n",
      "rkopis_znaleziony_saragossie_1501_librivox_64kb_mp3\n",
      "rose_garden_husband_1508_librivox_64kb_mp3\n",
      "roughriders_1503_librivox_64kb_mp3\n",
      "sabotage_in_space_1512_librivox_64kb_mp3\n",
      "sacred_meditations_1603_librivox_64kb_mp3\n",
      "san_francisco_earthquake_fire_mk_1505_librivox_64kb_mp3\n",
      "sexesinscienceandhistory_1508_librivox_64kb_mp3\n",
      "shininggateway_1501_librivox_64kb_mp3\n",
      "short_stories_hyun_1411_librivox_64kb_mp3\n",
      "short_stories_na_1412_librivox_64kb_mp3\n",
      "stine_1410_librivox_64kb_mp3\n",
      "story_of_one_short_life_1508_librivox_64kb_mp3\n",
      "symbolism_1510_librivox_64kb_mp3\n",
      "tausend_eine_nacht_2_1512_librivox_64kb_mp3\n",
      "tenfrominfinity_1603_librivox_64kb_mp3\n",
      "the_monastery_1501_librivox_64kb_mp3\n",
      "theodoric_the_goth_1509_librivox_64kb_mp3\n",
      "the_one-eyed_griffin_1411_librivox_64kb_mp3\n",
      "the_storm_1504_librivox_64kb_mp3\n",
      "thirdperson_1408_librivox_64kb_mp3\n",
      "threetimesandout_1412_librivox_64kb_mp3\n",
      "tour_dr_syntax_1601_librivox_64kb_mp3\n",
      "tower_of_london_1602_librivox_64kb_mp3\n",
      "tschun_1504_librivox_64kb_mp3\n",
      "twice_bought_1503_librivox_64kb_mp3\n",
      "uncle_of_an_angel_sm_1501_librivox_64kb_mp3\n",
      "uncletomscabin_1604_librivox_64kb_mp3\n",
      "unknown_to_history_1511_librivox_64kb_mp3\n",
      "visha_vahini_1512_librivox_64kb_mp3\n",
      "warden_1511_librivox_64kb_mp3\n",
      "weisse_naechte_1504_librivox_64kb_mp3\n",
      "wildknight_1508_librivox_64kb_mp3\n",
      "wildwales_sg_1506_librivox_64kb_mp3\n",
      "winning_his_spurs_1412_librivox_64kb_mp3\n",
      "worshipper_image_1410_librivox_64kb_mp3\n"
     ]
    }
   ],
   "source": [
    "# cleanup_split('audio-train-full')\n",
    "run_preprocess('audio-train-full', \"4200\", \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_features('audio-train-full', \"4200\", \"3\")\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/kishan.sheshagiri/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "l_enc = LabelEncoder()\n",
    "l_enc.fit(y_train)\n",
    "y_train_enc = l_enc.transform(y_train)\n",
    "y_train_norm = np_utils.to_categorical(y_train_enc)\n",
    "\n",
    "l_enc.fit(y_test)\n",
    "y_test_enc = l_enc.transform(y_test)\n",
    "y_test_norm = np_utils.to_categorical(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X, y, y_train_enc, y_test_enc, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), padding='same',\n",
    "                 input_shape=(64, 128, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(8, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(117))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98942 samples, validate on 42405 samples\n",
      "Epoch 1/5\n",
      "98942/98942 [==============================] - 109s 1ms/step - loss: 0.3437 - acc: 0.9727 - val_loss: 0.3776 - val_acc: 0.9627\n",
      "Epoch 2/5\n",
      "98942/98942 [==============================] - 109s 1ms/step - loss: 0.3384 - acc: 0.9741 - val_loss: 0.3824 - val_acc: 0.9607\n",
      "Epoch 3/5\n",
      "98942/98942 [==============================] - 109s 1ms/step - loss: 0.3374 - acc: 0.9743 - val_loss: 0.3723 - val_acc: 0.9656\n",
      "Epoch 4/5\n",
      "98942/98942 [==============================] - 110s 1ms/step - loss: 0.3339 - acc: 0.9753 - val_loss: 0.3736 - val_acc: 0.9644\n",
      "Epoch 5/5\n",
      "80928/98942 [=======================>......] - ETA: 18s - loss: 0.3373 - acc: 0.9756"
     ]
    }
   ],
   "source": [
    "# epoch = 1\n",
    "# while epoch <= 30:\n",
    "# model.load_weights('mfcc_model_weights_6030_3-5.h5')\n",
    "model.fit(np.array(X_train), y_train_norm,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          shuffle = True,\n",
    "         validation_data=(np.array(X_test), y_test_norm))\n",
    "#     model.save_weights('spect_model_weights_' + str(epoch) + '.h5')\n",
    "#     epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('mfcc_model_weights_4200_3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
