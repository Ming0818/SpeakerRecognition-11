{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from scikits.talkbox import lpc\n",
    "\n",
    "\n",
    "def convert_to_lpc(filename,number_of_coefficients):\n",
    "    wave, sr = lp.load(filename, mono=True, sr=None)\n",
    "    lpc_signal=lpc(wave,number_of_coefficients)\n",
    "    lpcc_signal=lpcc(lpc_signal[0],lpc_signal[1])\n",
    "    return lpcc_signal\n",
    "                    \n",
    "\n",
    "def lpcc(seq, err_term, order=None):\n",
    "    if order is None:\n",
    "        order = len(seq) - 1\n",
    "    lpcc_coeffs = [np.log(err_term), -seq[0]]\n",
    "    for n in xrange(2, order + 1):\n",
    "        # Use order + 1 as upper bound for the last iteration\n",
    "        upbound = (order + 1 if n > order else n)\n",
    "        lpcc_coef = -sum(i * lpcc_coeffs[i] * seq[n - i - 1]\n",
    "                         for i in xrange(1, upbound)) * 1. / upbound\n",
    "        lpcc_coef -= seq[n - 1] if n <= len(seq) else 0\n",
    "        lpcc_coeffs.append(lpcc_coef)\n",
    "    return lpcc_coeffs\n",
    "\n",
    "\n",
    "def run_preprocess(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "#             print(directory)\n",
    "            lpcc_data = []\n",
    "            npy_file = directory + '_' + 'lpcc' + '_'+ '.npy'\n",
    "            file_path = os.path.join(subdir, directory)\n",
    "            print(file_path)\n",
    "            for filename in os.listdir(file_path):\n",
    "                lpcc_data.append(convert_to_lpc(file_path+\"\\\\\"+filename,24))\n",
    "\n",
    "            np.save(os.path.join(subdir, directory, npy_file), np.asarray(lpcc_data))\n",
    "            print(np.asarray(lpcc_data).shape)\n",
    "        break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def rename_npy(root, length, split):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            npy_file = directory + '_' + length + '_' + split + '.npy'\n",
    "            new_npy_file = directory + '_' + 'mfcc' + '_' + str(512) + '_' + length + '_' + split + '.npy'\n",
    "            if os.path.isfile(os.path.join(subdir, directory, npy_file)):\n",
    "                shutil.move(os.path.join(subdir, directory, npy_file), os.path.join(subdir, directory, new_npy_file))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(root):\n",
    "    lpcc_data=[]\n",
    "    lpcc_label = []\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        count=0\n",
    "        for directory in dirs:\n",
    "            npy_file = directory + '_' + 'lpcc' + '_' + '.npy'\n",
    "            if(count==0):\n",
    "                lpcc_data= np.load(os.path.join(subdir, directory, npy_file))\n",
    "                lpcc_label=lpcc_data.shape[0]*[directory.split('.')[0]]\n",
    "            else:\n",
    "                lpcc=np.load(os.path.join(subdir, directory, npy_file))\n",
    "                lpcc_data=np.vstack((lpcc_data,lpcc))\n",
    "                lpcc_label += lpcc.shape[0] * [directory.split('.')[0]]\n",
    "            count+=1\n",
    "        break\n",
    "    return lpcc_data, lpcc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_split(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            shutil.rmtree(os.path.join(subdir, directory, \"split\"), ignore_errors = True)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def cleanup_merged(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            for f in glob.glob(os.path.join(subdir, directory, \"*_merged*.*\")):\n",
    "                os.remove(f)\n",
    "        break\n",
    "\n",
    "def cleanup_npy(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            for f in glob.glob(os.path.join(subdir, directory, \"*.npy\")):\n",
    "                os.remove(f)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_samples(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            shutil.move(os.path.join(subdir, directory), os.path.join(subdir, directory.split(\"_\")[0]))\n",
    "        break\n",
    "\n",
    "def remove_extra_samples(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            name_o = directory.split(\".\") \n",
    "            if len(name_o) == 2 and int(name_o[1]) > 10:\n",
    "                shutil.rmtree(os.path.join(subdir, directory))\n",
    "        break\n",
    "    \n",
    "def distribute_samples(root):\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for directory in dirs:\n",
    "            if len(directory.split(\".\")) != 1:\n",
    "                continue\n",
    "            for d_subdir, d_dirs, d_files in os.walk(os.path.join(root, directory)):\n",
    "                for i, sample in enumerate(d_files):\n",
    "                    os.makedirs(os.path.join(subdir, directory + \".\" + str(i + 1)))\n",
    "                    shutil.move(os.path.join(subdir, directory, sample), \\\n",
    "                                os.path.join(subdir, directory + \".\" + str(i + 1), sample))\n",
    "                break\n",
    "        remove_extra_samples(root)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\\1\n",
      "(292L, 25L)\n",
      "Training\\2\n",
      "(102L, 25L)\n",
      "Training\\3\n",
      "(109L, 25L)\n",
      "Training\\4\n",
      "(108L, 25L)\n",
      "Training\\5\n",
      "(97L, 25L)\n",
      "Training\\6\n",
      "(111L, 25L)\n",
      "Training\\7\n",
      "(81L, 25L)\n"
     ]
    }
   ],
   "source": [
    "# cleanup_split(data_dir)\n",
    "# cleanup_npy(data_dir)\n",
    "# rename_samples(data_dir)\n",
    "# distribute_samples(data_dir)\n",
    "run_preprocess(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900L, 25L)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "X, y = load_features(data_dir)\n",
    "X=np.asarray(X)\n",
    "y=np.asarray(y)\n",
    "X = X.reshape(X.shape[0], X.shape[1],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900L, 25L, 1L, 1L)\n",
      "(630L,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "l_enc = LabelEncoder()\n",
    "l_enc.fit(y_train)\n",
    "y_train_enc = l_enc.transform(y_train)\n",
    "y_train_norm = np_utils.to_categorical(y_train_enc)\n",
    "\n",
    "l_enc.fit(y_test)\n",
    "y_test_enc = l_enc.transform(y_test)\n",
    "y_test_norm = np_utils.to_categorical(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X, y, y_train_enc, y_test_enc, y_train, y_test\n",
    "X_train = X_train[:, :64, :, :]\n",
    "X_test = X_test[:, :64, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-1b2d8d238787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ashok\\AppData\\Local\\conda\\conda\\envs\\python3.5\\lib\\site-packages\\keras\\legacy\\interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu',\n",
    "                 input_shape=(25,1,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dense())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(y_test_norm[0])))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "ctr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='mfcc_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 24, 0, 32)         160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 0, 32)         0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 0, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 0, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 0, 32)         4128      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 0, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 0, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 0, 32)          0         \n",
      "=================================================================\n",
      "Total params: 4,288\n",
      "Trainable params: 4,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_6_input to have 4 dimensions, but got array with shape (630L, 25L, 1L)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-8b84b0825ff1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m          validation_data=(np.array(X_test), y_test_norm))\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Ashok\\AppData\\Local\\conda\\conda\\envs\\python3.5\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Ashok\\AppData\\Local\\conda\\conda\\envs\\python3.5\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ashok\\AppData\\Local\\conda\\conda\\envs\\python3.5\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ashok\\AppData\\Local\\conda\\conda\\envs\\python3.5\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_6_input to have 4 dimensions, but got array with shape (630L, 25L, 1L)"
     ]
    }
   ],
   "source": [
    "train_result = model.fit(np.array(X_train), y_train_norm,\n",
    "          batch_size=16,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          shuffle = True,\n",
    "         validation_data=(np.array(X_test), y_test_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('mfcc_model_weights_' + str(audio_len) + '_' + str(window_size) + '-' + str(n_mfcc) + '_' + str(ctr) + '.h5')\n",
    "ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.plot(train_result.history['acc'], color=\"#5599FF\")\n",
    "plt.plot(train_result.history['val_acc'], color=\"#55FF99\")\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
