{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train on 540 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 1.8987 - acc: 0.2889 - val_loss: 1.8220 - val_acc: 0.3139\n",
      "Epoch 2/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 1.8011 - acc: 0.3352 - val_loss: 1.7327 - val_acc: 0.3139\n",
      "Epoch 3/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 1.7104 - acc: 0.3593 - val_loss: 1.6219 - val_acc: 0.3139: 0s - loss: 1.7155 - acc: 0.356\n",
      "Epoch 4/50\n",
      "540/540 [==============================] - 0s 493us/step - loss: 1.6026 - acc: 0.3907 - val_loss: 1.4644 - val_acc: 0.4667\n",
      "Epoch 5/50\n",
      "540/540 [==============================] - 0s 550us/step - loss: 1.4600 - acc: 0.5148 - val_loss: 1.3527 - val_acc: 0.3778\n",
      "Epoch 6/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 1.3299 - acc: 0.5741 - val_loss: 1.1999 - val_acc: 0.4806\n",
      "Epoch 7/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 1.1632 - acc: 0.6463 - val_loss: 0.9842 - val_acc: 0.8139\n",
      "Epoch 8/50\n",
      "540/540 [==============================] - 0s 635us/step - loss: 1.0071 - acc: 0.7352 - val_loss: 0.8602 - val_acc: 0.7306\n",
      "Epoch 9/50\n",
      "540/540 [==============================] - 0s 552us/step - loss: 0.8780 - acc: 0.7593 - val_loss: 0.8011 - val_acc: 0.7972\n",
      "Epoch 10/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.7637 - acc: 0.7944 - val_loss: 0.6010 - val_acc: 0.8750\n",
      "Epoch 11/50\n",
      "540/540 [==============================] - 0s 491us/step - loss: 0.6398 - acc: 0.8222 - val_loss: 0.5194 - val_acc: 0.9028\n",
      "Epoch 12/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.5520 - acc: 0.8519 - val_loss: 0.5080 - val_acc: 0.8694\n",
      "Epoch 13/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.5344 - acc: 0.8537 - val_loss: 0.4508 - val_acc: 0.8694\n",
      "Epoch 14/50\n",
      "540/540 [==============================] - 0s 461us/step - loss: 0.4824 - acc: 0.8611 - val_loss: 0.3640 - val_acc: 0.9028\n",
      "Epoch 15/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.4467 - acc: 0.8722 - val_loss: 0.3303 - val_acc: 0.9111\n",
      "Epoch 16/50\n",
      "540/540 [==============================] - 0s 437us/step - loss: 0.3792 - acc: 0.8889 - val_loss: 0.3070 - val_acc: 0.9222\n",
      "Epoch 17/50\n",
      "540/540 [==============================] - 0s 520us/step - loss: 0.3535 - acc: 0.8963 - val_loss: 0.2804 - val_acc: 0.9222\n",
      "Epoch 18/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.3249 - acc: 0.9278 - val_loss: 0.2542 - val_acc: 0.9306\n",
      "Epoch 19/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.3085 - acc: 0.9185 - val_loss: 0.2519 - val_acc: 0.9167\n",
      "Epoch 20/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.2912 - acc: 0.9093 - val_loss: 0.2303 - val_acc: 0.9333\n",
      "Epoch 21/50\n",
      "540/540 [==============================] - 0s 550us/step - loss: 0.2537 - acc: 0.9352 - val_loss: 0.2125 - val_acc: 0.9389\n",
      "Epoch 22/50\n",
      "540/540 [==============================] - 0s 469us/step - loss: 0.2605 - acc: 0.9389 - val_loss: 0.1861 - val_acc: 0.9500\n",
      "Epoch 23/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.2319 - acc: 0.9370 - val_loss: 0.1615 - val_acc: 0.9583\n",
      "Epoch 24/50\n",
      "540/540 [==============================] - 0s 609us/step - loss: 0.2101 - acc: 0.9556 - val_loss: 0.2061 - val_acc: 0.9278\n",
      "Epoch 25/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.2364 - acc: 0.9259 - val_loss: 0.1428 - val_acc: 0.9667\n",
      "Epoch 26/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.2043 - acc: 0.9407 - val_loss: 0.1568 - val_acc: 0.9500\n",
      "Epoch 27/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.1810 - acc: 0.9463 - val_loss: 0.1448 - val_acc: 0.9611\n",
      "Epoch 28/50\n",
      "540/540 [==============================] - 0s 493us/step - loss: 0.1691 - acc: 0.9500 - val_loss: 0.1407 - val_acc: 0.9583\n",
      "Epoch 29/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.1538 - acc: 0.9648 - val_loss: 0.1105 - val_acc: 0.9667\n",
      "Epoch 30/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.1368 - acc: 0.9593 - val_loss: 0.1057 - val_acc: 0.9639\n",
      "Epoch 31/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.1317 - acc: 0.9648 - val_loss: 0.1030 - val_acc: 0.9750\n",
      "Epoch 32/50\n",
      "540/540 [==============================] - 0s 493us/step - loss: 0.1408 - acc: 0.9611 - val_loss: 0.1193 - val_acc: 0.9667\n",
      "Epoch 33/50\n",
      "540/540 [==============================] - 0s 550us/step - loss: 0.1175 - acc: 0.9741 - val_loss: 0.0892 - val_acc: 0.9778\n",
      "Epoch 34/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.1193 - acc: 0.9722 - val_loss: 0.0855 - val_acc: 0.9750\n",
      "Epoch 35/50\n",
      "540/540 [==============================] - 0s 520us/step - loss: 0.0999 - acc: 0.9815 - val_loss: 0.0787 - val_acc: 0.9778\n",
      "Epoch 36/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.0927 - acc: 0.9759 - val_loss: 0.0778 - val_acc: 0.9778\n",
      "Epoch 37/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.0926 - acc: 0.9778 - val_loss: 0.0629 - val_acc: 0.9889\n",
      "Epoch 38/50\n",
      "540/540 [==============================] - 0s 550us/step - loss: 0.1080 - acc: 0.9778 - val_loss: 0.0719 - val_acc: 0.9833\n",
      "Epoch 39/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.1038 - acc: 0.9796 - val_loss: 0.0704 - val_acc: 0.9778\n",
      "Epoch 40/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.0915 - acc: 0.9778 - val_loss: 0.0627 - val_acc: 0.9861\n",
      "Epoch 41/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.0893 - acc: 0.9778 - val_loss: 0.0501 - val_acc: 0.9917\n",
      "Epoch 42/50\n",
      "540/540 [==============================] - 0s 522us/step - loss: 0.0806 - acc: 0.9815 - val_loss: 0.0499 - val_acc: 0.9889\n",
      "Epoch 43/50\n",
      "540/540 [==============================] - 0s 580us/step - loss: 0.0729 - acc: 0.9815 - val_loss: 0.0475 - val_acc: 0.9972\n",
      "Epoch 44/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.0957 - acc: 0.9704 - val_loss: 0.0459 - val_acc: 0.9944\n",
      "Epoch 45/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.0713 - acc: 0.9889 - val_loss: 0.0447 - val_acc: 0.9944\n",
      "Epoch 46/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.0647 - acc: 0.9852 - val_loss: 0.0429 - val_acc: 0.9944\n",
      "Epoch 47/50\n",
      "540/540 [==============================] - 0s 463us/step - loss: 0.0608 - acc: 0.9815 - val_loss: 0.0399 - val_acc: 0.9944\n",
      "Epoch 48/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.0690 - acc: 0.9870 - val_loss: 0.0367 - val_acc: 0.9972\n",
      "Epoch 49/50\n",
      "540/540 [==============================] - 0s 435us/step - loss: 0.0714 - acc: 0.9796 - val_loss: 0.0383 - val_acc: 0.9917\n",
      "Epoch 50/50\n",
      "540/540 [==============================] - 0s 433us/step - loss: 0.0710 - acc: 0.9778 - val_loss: 0.0371 - val_acc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa as lp\n",
    "import subprocess\n",
    "import os\n",
    "from IPython.core.debugger import set_trace\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from scikits.talkbox import lpc\n",
    "\n",
    "print(1)\n",
    "# This function is to convert mp3 to wav currently in disuse\n",
    "def convert_audio_to_wav(filename):\n",
    "    subprocess.call(['ffmpeg', '-i', filename,\n",
    "                   str(filename.split(\".mp3\")[0])+\".wav\"])\n",
    "    \n",
    "#Function to convert mp3 audio to lpc shapes    \n",
    "def convert_to_lpc(filename,number_of_coefficients):\n",
    "    wave, sr = lp.load(filename, mono=True, sr=None)\n",
    "    lpc_signal=lpc(wave,number_of_coefficients)\n",
    "    processed_lpc_signal=[[0.00 for x in range(number_of_coefficients+1)] for y in range(len(lpc_signal)) ]\n",
    "    for i in range(len(lpc_signal)):\n",
    "        for j in range(len(lpc_signal[i])):\n",
    "            processed_lpc_signal[i][j]=lpc_signal[i][j]\n",
    "    return processed_lpc_signal\n",
    "                    \n",
    "\n",
    "\n",
    "def create_training_data(pathname_training,number_of_coefficients):\n",
    "    #set_trace()\n",
    "    lpc_array=[]\n",
    "    subdirs=[x[1] for x in os.walk(pathname_training)][0]\n",
    "    for subdir in subdirs:\n",
    "        subdir_path=pathname_training+\"\\\\\" + subdir\n",
    "        files2=[x[2] for x in os.walk(subdir_path)][0]\n",
    "        for file_name in files2:\n",
    "            file_path=subdir_path+\"\\\\\"+file_name\n",
    "            lpc_of_file=convert_to_lpc(file_path,number_of_coefficients)\n",
    "            lpc_array.append(lpc_of_file)\n",
    "        np.save(os.getcwd()+\"\\\\lpc_files\\\\\"+subdir,lpc_array)\n",
    "        lpc_array=[]\n",
    "\n",
    " \n",
    "\n",
    "def get_lpc_from_file(location_of_lpc):\n",
    "    lpc_files=os.listdir(location_of_lpc)\n",
    "    return lpc_files\n",
    "\n",
    "#get_lpc_from_file( os.getcwd()+\"\\\\lpc_files\")\n",
    "\n",
    "def get_train_test(ratio_of_split, random_state=42):\n",
    "    # Get available labels\n",
    "    lpc_labels= get_lpc_from_file( os.getcwd()+\"\\\\lpc_files\")\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(os.getcwd()+\"\\\\lpc_files\\\\\"+lpc_labels[0])\n",
    "    y = np.zeros(X.shape[0])\n",
    "    \n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(lpc_labels[1:]):\n",
    "        x = np.load(os.getcwd()+\"\\\\lpc_files\\\\\"+label)\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - ratio_of_split), random_state=random_state, shuffle=True)\n",
    "\n",
    "def create_model(number_of_coefficients):\n",
    "    create_training_data(\"C:\\Users\\Ashok\\Documents\\GitHub\\SpeakerRecognition\\Training\",number_of_coefficients) \n",
    "    X_train, X_test, y_train, y_test = get_train_test(0.6)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3,number_of_coefficients+1, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3,number_of_coefficients+1, 1)\n",
    "    y_train_hot = to_categorical(y_train)\n",
    "    y_test_hot = to_categorical(y_test)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(3,number_of_coefficients+1, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train_hot, batch_size=100, epochs=50, verbose=1, validation_data=(X_test, y_test_hot))\n",
    "    \n",
    "\n",
    "create_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
